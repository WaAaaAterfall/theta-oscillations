{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User settings\n",
    "\n",
    "---\n",
    "\n",
    "1) Keep the file structure like this:\n",
    "\n",
    "    normaliser_data/\n",
    "    \n",
    "        Subject01_YG/\n",
    "                HDF5/\n",
    "                    fp_deepinsight and trained model...\n",
    "                Intermediate_data/ \n",
    "                     intermediate .npy file & results\n",
    "                Plot/\n",
    "                    store the plot results\n",
    "                Recordings/\n",
    "                    ...\n",
    "                VideoGame/\n",
    "                    ...\n",
    "                Info/\n",
    "                    ...\n",
    "                    \n",
    "        Subject02_JY/\n",
    "                HDF5/\n",
    "                    fp_deepinsight and trained model...\n",
    "                Intermediate_data/ \n",
    "                     intermediate .npy file & results\n",
    "                Plot/\n",
    "                    store the plot results\n",
    "                Recordings/\n",
    "                    ...\n",
    "                VideoGame/\n",
    "                    ...\n",
    "                Info/\n",
    "                    ...\n",
    "                    \n",
    "                    \n",
    "2)  Then set the subject number to run this pipelineâ†“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from plotly.offline import iplot\n",
    "import plotly.graph_objs as go\n",
    "from skimage import io\n",
    "\n",
    "import mne\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "import h5py\n",
    "import numpy as np# Functions & Dataset\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import time\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_folder = '/Volumes/t7/dku2023/ieeg/'\n",
    "main_folder = 'F:/dku2023/ieeg/'\n",
    "\n",
    "file_paths = {}\n",
    "\n",
    "\n",
    "file_paths[1] = {}\n",
    "file_paths[1]['folder'] = main_folder+'normaliser_data/Subject01_YG/'\n",
    "file_paths[1]['recordings'] = main_folder+'normaliser_data/Subject01_YG/Recordings/yangge0108_navi.edf'\n",
    "file_paths[1]['ttl']        = main_folder+'normaliser_data/Subject01_YG/Recordings/Subject01_YG_part2_ttlMarkerNew.txt'\n",
    "file_paths[1]['game']       = main_folder+'normaliser_data/Subject01_YG/VideoGame/YG20210108Normaliser_navigation_20210108_142413.txt'\n",
    "file_paths[1]['info'] = {}\n",
    "file_paths[1]['info']['name'] = 'YG'\n",
    "\n",
    "file_paths[2] = {}\n",
    "file_paths[2]['folder'] = main_folder+'normaliser_data/Subject02_JY/'\n",
    "file_paths[2]['recordings'] = main_folder+'normaliser_data/Subject02_JY/Recordings/jinyong0118_navi.edf'\n",
    "file_paths[2]['ttl']        = main_folder+'normaliser_data/Subject02_JY/Recordings/Subject02_JY_ttlMarkerNew.txt'\n",
    "file_paths[2]['game']       = main_folder+'normaliser_data/Subject02_JY/VideoGame/Normaliser_navigation_20210118_144504.txt'\n",
    "file_paths[2]['info'] = {}\n",
    "file_paths[2]['info']['name'] = 'JY'\n",
    "\n",
    "file_paths[3] = {}\n",
    "file_paths[3]['folder'] = main_folder+'normaliser_data/Subject03_LYY/'\n",
    "file_paths[3]['recordings'] = main_folder+'normaliser_data/Subject03_LYY/Recordings/linyiyou031002.edf'\n",
    "file_paths[3]['ttl']        = main_folder+'normaliser_data/Subject03_LYY/Recordings/Subject03_LYY_ttlMarkerNew.txt'\n",
    "file_paths[3]['game']       = main_folder+'normaliser_data/Subject03_LYY/VideoGame/Normaliser_navigation_20210310_171054.txt'\n",
    "file_paths[3]['info'] = {}\n",
    "file_paths[3]['info']['name'] = 'LYY'\n",
    "\n",
    "file_paths[4] = {}\n",
    "file_paths[4]['folder'] = main_folder+'normaliser_data/Subject04_YY/'\n",
    "file_paths[4]['recordings'] = main_folder+'normaliser_data/Subject04_YY/Recordings/yuyue0504.edf'\n",
    "file_paths[4]['ttl']        = main_folder+'normaliser_data/Subject04_YY/Recordings/Subject04_YY_ttlMarkerNew.txt'\n",
    "file_paths[4]['game']       = main_folder+'normaliser_data/Subject04_YY/VideoGame/Normaliser_navigation_20210504_135840.txt'\n",
    "file_paths[4]['info'] = {}\n",
    "file_paths[4]['info']['name'] = 'YY'\n",
    "\n",
    "file_paths[6] = {}\n",
    "file_paths[6]['folder'] = main_folder+'normaliser_data/Subject06_ZQ/'\n",
    "file_paths[6]['recordings'] = main_folder+'normaliser_data/Subject06_ZQ/Recordings/zhengqiao0531.edf'\n",
    "file_paths[6]['ttl']        = main_folder+'normaliser_data/Subject06_ZQ/Recordings/Subject06_ZQ_ttlMarkerNew.txt'\n",
    "file_paths[6]['game']       = main_folder+'normaliser_data/Subject06_ZQ/VideoGame/Normaliser_navigation_20210531_095712Zhengqiao.txt'\n",
    "file_paths[6]['info'] = {}\n",
    "file_paths[6]['info']['name'] = 'ZQ'\n",
    "\n",
    "file_paths[7] = {}\n",
    "file_paths[7]['folder'] = main_folder+'normaliser_data/Subject07_CLC/'\n",
    "file_paths[7]['recordings'] = main_folder+'normaliser_data/Subject07_CLC/Recordings/chenlinchao07233.edf'\n",
    "file_paths[7]['ttl']        = main_folder+'normaliser_data/Subject07_CLC/Recordings/Subject07_CLC_ttlMarkerNew.txt'\n",
    "file_paths[7]['game']       = main_folder+'normaliser_data/Subject07_CLC/VideoGame/chenlinchao_Normaliser_navigation_20210723_123129.txt'\n",
    "file_paths[7]['info'] = {}\n",
    "file_paths[7]['info']['name'] = 'CLC'\n",
    "\n",
    "file_paths[8] = {}\n",
    "file_paths[8]['folder'] = main_folder+'normaliser_data/Subject08_SCM/'\n",
    "file_paths[8]['recordings'] = main_folder+'normaliser_data/Subject08_SCM/Recordings/shenchunmei07301.edf'\n",
    "file_paths[8]['ttl']        = main_folder+'normaliser_data/Subject08_SCM/Recordings/Subject08_SCM_ttlMarkerNew.txt'\n",
    "file_paths[8]['game']       = main_folder+'normaliser_data/Subject08_SCM/VideoGame/scm_Normaliser_navigation_20210730_151846.txt'\n",
    "file_paths[8]['info'] = {}\n",
    "file_paths[8]['info']['name'] = 'SCM'\n",
    "\n",
    "file_paths[9] = {}\n",
    "file_paths[9]['folder'] =main_folder+'normaliser_data/Subject09_LZ/'\n",
    "file_paths[9]['recordings'] = main_folder+'normaliser_data/Subject09_LZ/Recordings/liuzhe08251.edf'\n",
    "file_paths[9]['ttl']        = main_folder+'normaliser_data/Subject09_LZ/Recordings/Subject09_LZ_ttlMarkerNew.txt'\n",
    "file_paths[9]['game']       = main_folder+'normaliser_data/Subject09_LZ/VideoGame/Liuzhe_Normaliser_navigation_20210825_103719.txt'\n",
    "file_paths[9]['info'] = {}\n",
    "file_paths[9]['info']['name'] = 'LZ'\n",
    "\n",
    "file_paths[10] = {}\n",
    "file_paths[10]['folder'] = main_folder+'normaliser_data/Subject10_ZLX/'\n",
    "file_paths[10]['recordings'] = main_folder+'normaliser_data/Subject10_ZLX/Recordings/zhoulongxin09031.edf'\n",
    "file_paths[10]['ttl']        = main_folder+'normaliser_data/Subject10_ZLX/Recordings/Subject10_1_ttlMarkerNew.txt'\n",
    "file_paths[10]['game']       = main_folder+'normaliser_data/Subject10_ZLX/VideoGame/zhoulongxin_Normaliser_navigation_20210903_103923.txt'\n",
    "file_paths[10]['info'] = {}\n",
    "file_paths[10]['info']['name'] = 'ZLX'\n",
    "\n",
    "file_paths[11] = {}\n",
    "file_paths[11]['folder'] = main_folder+'normaliser_data/Subject11_WCF/'\n",
    "file_paths[11]['recordings'] = main_folder+'normaliser_data/Subject10_ZLX/Recordings/wangchunfei0927.edf'\n",
    "file_paths[11]['ttl']        = main_folder+'normaliser_data/Subject10_ZLX/Recordings/Subject11_ttlMarkerNew.txt'\n",
    "file_paths[11]['game']       = main_folder+'normaliser_data/Subject10_ZLX/VideoGame/wangchunfei_Normaliser_navigation_20210927_161155.txt'\n",
    "file_paths[11]['info'] = {}\n",
    "file_paths[11]['info']['name'] = 'ZLX'\n",
    "hpc_chan2 = {}\n",
    "\n",
    "hpc_chan2[1] = ['POL B1', 'POL N1']\n",
    "hpc_chan2[2] = ['POL B1', 'POL D3']\n",
    "hpc_chan2[3] = ['POL E1']\n",
    "hpc_chan2[4] = ['POL I2']\n",
    "hpc_chan2[7] = ['POL I3']\n",
    "hpc_chan2[8] = ['POL J1','EEG C1-Ref']\n",
    "hpc_chan2[9] = ['EEG A1-Ref','POL B2']\n",
    "hpc_chan2[10] = ['POL K1','EEG A1-Ref']\n",
    "\n",
    "### Use this selection for bipolarizing\n",
    "# hpc_chan2[1] = ['POL B1','POL B2']\n",
    "# hpc_chan2[2] = ['POL B1', 'POL D3']\n",
    "# hpc_chan2[3] = ['POL E1','POL E2']\n",
    "# hpc_chan2[4] = ['POL I2','POL I3']\n",
    "# hpc_chan2[7] = ['POL I3', 'POL I4']\n",
    "# hpc_chan2[8] = ['POL J1','POL J2']\n",
    "\n",
    "# deepInsight_encode =  file_paths[sub]['folder'] + 'HDF5/deepInsight_encode.h5' \n",
    "# fp_plot = file_paths[sub]['folder'] + 'Plot/'\n",
    "# fp_data = file_paths[sub]['folder'] + 'Intermediate_data/'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## necessary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and parsing each trial video game feature\n",
    "def structure_gamelog(gamelog):\n",
    "\n",
    "    trials_data = {}\n",
    "\n",
    "    reading_navigation_positions = False\n",
    "\n",
    "    for line in gamelog:\n",
    "\n",
    "\n",
    "        if line.startswith('Trial ended'):\n",
    "            trials_data[trial_n]['Trial_ended_time'] = float(line.split(' ')[-1]) \n",
    "\n",
    "            trial_duration = trials_data[trial_n]['Trial_ended_time'] - trials_data[trial_n]['Trial_start_time']\n",
    "            trials_data[trial_n]['trial_duration'] = trial_duration\n",
    "            trials_data[trial_n]['n_of_objects'] = len(trials_data[trial_n]['Objects_location'])\n",
    "\n",
    "            trials_data[trial_n]['Navigation'] = np.array(trials_data[trial_n]['Navigation'])\n",
    "            \n",
    "            ### Compute velocity from position (navigation) coordinates\n",
    "            trial_duration = trials_data[trial_n]['Navigation'][:,0][-1] - trials_data[trial_n]['Navigation'][:,0][0]\n",
    "            # trial_distance in meters\n",
    "            trial_distance = np.sum(np.abs(np.diff(trials_data[trial_n]['Navigation'][:,1] +1j* trials_data[trial_n]['Navigation'][:,2])))\n",
    "            trials_data[trial_n]['Velocity'] = trial_distance/trial_duration\n",
    "            \n",
    "            \n",
    "            trials_data[trial_n]['Objects_location'] = np.array(trials_data[trial_n]['Objects_location'])\n",
    "\n",
    "            # trial_distance in angles\n",
    "            trial_distance = np.unwrap( np.angle( trials_data[trial_n]['Navigation'][:,1] +1j* trials_data[trial_n]['Navigation'][:,2] ) )\n",
    "            trial_distance = trial_distance[-1] - trial_distance[0]\n",
    "            trials_data[trial_n]['Trial_distance'] = trial_distance\n",
    "\n",
    "            ### cue/sec needs to get how many laps were performed and ajust it to the number of items per every lap (2pi)\n",
    "            this_trial_crossed_objects = trial_distance  * trials_data[trial_n]['n_of_objects'] / np.pi*2\n",
    "            trial_cue_per_sec = trials_data[trial_n]['trial_duration'] / this_trial_crossed_objects\n",
    "            trials_data[trial_n]['trial_cue_per_sec'] = trial_cue_per_sec\n",
    "\n",
    "\n",
    "            reading_navigation_positions = False\n",
    "\n",
    "\n",
    "        if reading_navigation_positions==False:\n",
    "\n",
    "            if line.startswith('Trial number'): \n",
    "                trial_n = int(line.split(': ')[1][:-1])\n",
    "                trials_data[trial_n] = {}\n",
    "            if line.startswith('Speed'): \n",
    "                trials_data[trial_n]['Speed'] = float(line.split('Speed: ')[1][:-1])\n",
    "            if line.startswith('Ring_size'): \n",
    "                trials_data[trial_n]['Ring_size'] = float(line.split('Ring_size: ')[1][:-1])\n",
    "\n",
    "            if line.startswith('Objects location'):\n",
    "                ### actualItem  +\" \"+ itemX +\" \"+ itemZ +\" \"+ itemAngle\n",
    "                trials_data[trial_n]['Objects_location'] = []\n",
    "            if line.startswith('Item:'):\n",
    "                trials_data[trial_n]['Objects_location'].append( np.array(line.split('Item: ')[1][:-1].split(' ')).astype(float) )\n",
    "\n",
    "            if line.startswith('Trial start'):\n",
    "                trials_data[trial_n]['Navigation'] = []\n",
    "                reading_navigation_positions = True\n",
    "                trials_data[trial_n]['Trial_start_time'] = float(line.split(' ')[-1]) \n",
    "\n",
    "\n",
    "            if line.startswith('Question onset'):\n",
    "                trials_data[trial_n]['Testing'] = {}\n",
    "                trials_data[trial_n]['Testing']['Question_onset'] = float(line.split('Question onset ')[1][:-1])\n",
    "\n",
    "            if line.startswith('Testing'):            \n",
    "                tmp_line = line[:-1].split(' ')\n",
    "                trials_data[trial_n]['Testing']['response_time'] = float(tmp_line[1])\n",
    "                trials_data[trial_n]['Testing']['cued_object'] = int(tmp_line[3])\n",
    "                trials_data[trial_n]['Testing']['option_1'] = int(tmp_line[5])\n",
    "                trials_data[trial_n]['Testing']['option_2'] = int(tmp_line[7])\n",
    "                trials_data[trial_n]['Testing']['asnwered_object'] = int(tmp_line[9])\n",
    "                trials_data[trial_n]['Testing']['asnwered_key'] = tmp_line[11]\n",
    "\n",
    "        elif reading_navigation_positions==True:\n",
    "            trials_data[trial_n]['Navigation'].append( np.array(line[:-1].split(' ')).astype(float) )\n",
    "\n",
    "    return trials_data\n",
    "\n",
    "\n",
    "def interp_f(behavioural_signal, lfp_size):\n",
    "    n_samples = len(behavioural_signal)\n",
    "    x = np.linspace(0, n_samples, num=n_samples, endpoint=True)\n",
    "    interpolate_f = interp1d(x, behavioural_signal, kind='linear')\n",
    "    new_sampling_space = np.linspace(0, n_samples, num=lfp_size, endpoint=True)\n",
    "    return interpolate_f(new_sampling_space)\n",
    "\n",
    "\n",
    "def get_behavioral_position(trials_data, trial_number):\n",
    "    position_array = []\n",
    "    for count in range(len(trials_data[trial_number]['Navigation'])):\n",
    "        time = trials_data[trial_number]['Navigation'][count][0]\n",
    "        x = trials_data[trial_number]['Navigation'][count][1]\n",
    "        y = trials_data[trial_number]['Navigation'][count][2]\n",
    "        position_array.append([trial_number, time, x, y])\n",
    "        \n",
    "    return np.array(position_array)\n",
    "\n",
    "\n",
    "'''\n",
    "Extract navigation data from recording txt file\n",
    "Return:\n",
    "    data selected from hippocampol channel, \n",
    "    lfp_theta_filtered, applied norch and theta filter on raw data\n",
    "    trials_data, extract from game log, see def struct_gamelog\n",
    "    event_samples, TTL information and index for navigation start, end...etc\n",
    "    int(raw.info['sfreq']) s_frequency info\n",
    "'''\n",
    "def get_subject_data(sub, file_paths, hpc_chan2):\n",
    "\n",
    "    # Load brain recordings\n",
    "    raw = mne.io.read_raw_edf(file_paths[sub]['recordings'])\n",
    "    print(\"all channel name:\", raw.ch_names)\n",
    "    #print(np.shape(raw))\n",
    "    # Load TTL events\n",
    "    TTL = pd.read_csv(file_paths[sub]['ttl'],\n",
    "                      sep=' ',\n",
    "                      names=['time', 'type', 'n'])\n",
    "    #print(TTL)\n",
    "\n",
    "    # Get hippocampal channels of this subject\n",
    "    sub_hpc_chans = hpc_chan2[sub]\n",
    "    data = raw.get_data(picks=sub_hpc_chans)\n",
    "\n",
    "    # Load videoGame data and structure it by trials\n",
    "    gamelog = []\n",
    "    with open(file_paths[sub]['game'], 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            gamelog.append(line)\n",
    "    trials_data = structure_gamelog(gamelog)\n",
    "\n",
    "    ### Load the signal\n",
    "    # Here loading 2 signals in the Amygdala. This will be specific for each patient.\n",
    "    lfps = raw.get_data(picks=sub_hpc_chans)\n",
    "\n",
    "    ## Notch is done to remove the noise from the power line in the building. Since China operates on a 220V voltage and 50Hz and remove the 50Hz and its harmonics (100, 150, etc) to the signal.\n",
    "    lfp_bp_notch = mne.filter.notch_filter(lfps,\n",
    "                                           raw.info['sfreq'],\n",
    "                                           [50., 100., 150., 200.],\n",
    "                                           notch_widths=.1)\n",
    "#   lfp_bp_notch = lfp_bp_notch[0] - lfp_bp_notch[1]\n",
    "    low_freq = 2\n",
    "    high_freq = 10\n",
    "\n",
    "    lfp_theta_filtered = mne.filter.filter_data(lfp_bp_notch, int(raw.info['sfreq']), low_freq, high_freq, verbose=False )\n",
    "\n",
    "    ### TTL markers\n",
    "    event_samples = np.vstack((\n",
    "        TTL[TTL['type'] == 2]['time'].values,\n",
    "        TTL[TTL['type'] == 3]['time'].values,\n",
    "        TTL[TTL['type'] == 4]['time'].values,\n",
    "        TTL[TTL['type'] == 5]['time'].values,\n",
    "    )).T\n",
    "\n",
    "    return data, lfp_theta_filtered, trials_data, event_samples, int(raw.info['sfreq'])\n",
    "\n",
    "\n",
    "'''\n",
    "Deal with ieeg signal data\n",
    "Return: \n",
    "a dict with essential information\n",
    "physilogical data: a list of the ieeg signal between navigation for all trials\n",
    "timestamps: a list of index matching physilogical data\n",
    "position_2d: coordinate..ish matching each timestamp\n",
    "event_marker: \n",
    "'''\n",
    "def get_preprocess_data(trials_data,markers,physilogical_data,start_end_indice=[0,1],test=False): #trials, event_sample, notch_filtered_data\n",
    "    \n",
    "    '''\n",
    "    start_end_indice:\n",
    "        markers[:][0] the start of one trial\n",
    "        markers[:][1] the end of one trial\n",
    "        markers[:][2] the onset of the testing question\n",
    "        markers[:][3] the onset of response\n",
    "    test: \n",
    "        True: decode the recall part, no real output(position)\n",
    "    '''\n",
    "    physilogical_data_navi= {}\n",
    "\n",
    "    for chan in range(physilogical_data.shape[0]):\n",
    "        \n",
    "        for trial_num in range(min(len(trials_data), len(markers))):  \n",
    "            behavioural_signal = get_behavioral_position(trials_data, trial_num)\n",
    "            navi_start = int(markers[trial_num][start_end_indice[0]])\n",
    "            navi_stop = int(markers[trial_num][start_end_indice[1]])\n",
    "            lfp_size = abs(navi_stop - navi_start)\n",
    "            \n",
    "            if (chan == 0) & (trial_num == 0):\n",
    "                start_array = np.array([lfp_size])\n",
    "                timestamps = np.linspace(navi_start,navi_stop-1,lfp_size, dtype=int)\n",
    "                if test == False :\n",
    "                    position_2d = np.vstack(( interp_f(behavioural_signal.T[2], lfp_size) , interp_f(behavioural_signal.T[3], lfp_size)))\n",
    "                \n",
    "            if (chan == 0) & (trial_num > 0):\n",
    "                start_array = np.hstack((start_array,np.array([int(start_array[trial_num-1])+lfp_size])))\n",
    "                timestamps = np.hstack(( timestamps, np.linspace(navi_start,navi_stop-1,lfp_size, dtype=int) ))\n",
    "                if test == False :\n",
    "                    position_2d = np.hstack((position_2d, np.vstack(( interp_f(behavioural_signal.T[2], lfp_size) , interp_f(behavioural_signal.T[3], lfp_size)))  ))\n",
    "                \n",
    "            if trial_num == 0:\n",
    "                physilogical_data_navi[chan]= physilogical_data[chan][navi_start:navi_stop]\n",
    "                \n",
    "            if trial_num > 0:\n",
    "                physilogical_data_navi[chan]  = np.hstack((physilogical_data_navi[chan], physilogical_data[chan][navi_start:navi_stop] ))\n",
    "    \n",
    "    print(np.shape(timestamps))\n",
    "    print(np.shape(start_array))\n",
    "    print(np.shape(np.array([physilogical_data_navi[i] for i in range(len(physilogical_data_navi))]).T))\n",
    "    if test == True :\n",
    "        return {\n",
    "            'physilogical_data': np.array([physilogical_data_navi[i] for i in range(len(physilogical_data_navi))]).T,\n",
    "            'timestamps': timestamps,\n",
    "            'event_marker_each_trial': start_array\n",
    "        }\n",
    "    if test == False :               \n",
    "        return {\n",
    "            'physilogical_data': np.array([physilogical_data_navi[i] for i in range(len(physilogical_data_navi))]).T,\n",
    "            'timestamps': timestamps,\n",
    "            'position_2d': position_2d,\n",
    "            'event_marker_each_trial': start_array\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Number of Theta Cycles from physilogical data nad event sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from F:\\dku2023\\ieeg\\normaliser_data\\Subject10_ZLX\\Recordings\\zhoulongxin09031.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\River\\AppData\\Local\\Temp\\ipykernel_17588\\2422287699.py:115: RuntimeWarning:\n",
      "\n",
      "Channel names are not unique, found duplicates for: {'EEG M1-Ref', 'EEG F3-Ref', 'EEG C4-Ref', 'EEG C3-Ref', 'POL 00', 'EEG M2-Ref', 'POL 0', 'EEG F4-Ref'}. Applying running numbers for duplicates.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all channel name: ['EEG A1-Ref', 'EEG A2-Ref', 'POL A3', 'POL A4', 'POL A5', 'POL A6', 'POL A7', 'POL A8', 'POL A9', 'POL A10', 'POL B1', 'POL B2', 'POL B3', 'POL B4', 'POL B5', 'POL B6', 'POL B7', 'POL B8', 'POL B9', 'POL E', 'POL B10', 'EEG C1-Ref', 'POL A11', 'POL A12', 'EEG C2-Ref', 'EEG C3-Ref-0', 'EEG C4-Ref-0', 'EEG C5-Ref', 'EEG C6-Ref', 'POL C7', 'POL C8', 'POL C9', 'POL C10', 'POL C11', 'POL C12', 'POL D1', 'POL D2', 'POL DC01', 'POL DC02', 'POL DC03', 'POL DC04', 'POL DC05', 'POL DC06', 'POL DC07', 'POL DC08', 'POL DC09', 'POL DC10', 'POL DC11', 'POL DC12', 'POL DC13', 'POL DC14', 'POL DC15', 'POL DC16', 'POL D3', 'POL D4', 'POL D5', 'POL D6', 'POL D7', 'POL D8', 'POL D9', 'POL D10', 'POL E1', 'POL E2', 'POL E3', 'POL E4', 'POL E5', 'POL E6', 'POL E7', 'POL E8', 'POL E9', 'POL E10', 'POL E11', 'POL E12', 'EEG F1-Ref', 'EEG F2-Ref', 'EEG F3-Ref-0', 'EEG F4-Ref-0', 'EEG F5-Ref', 'EEG F6-Ref', 'EEG F7-Ref', 'EEG F8-Ref', 'POL G1', 'POL G2', 'POL G3', 'POL G4', 'POL G5', 'POL G6', 'POL G7', 'POL G8', 'POL H1', 'POL H2', 'POL H3', 'POL H4', 'POL H5', 'POL H6', 'POL H7', 'POL H8', 'POL H9', 'POL H10', 'POL I1', 'POL I2', 'POL I3', 'POL I4', 'POL I5', 'POL I6', 'POL I7', 'POL I8', 'POL I9', 'POL I10', 'POL I11', 'POL I12', 'POL I13', 'POL I14', 'POL I15', 'POL I16', 'POL J1', 'POL J2', 'POL J3', 'POL J4', 'POL J5', 'POL J6', 'POL J7', 'POL J8', 'POL J9', 'POL J10', 'POL J11', 'POL J12', 'POL J13', 'POL J14', 'POL K1', 'POL K2', 'POL K3', 'POL K4', 'POL K5', 'POL K6', 'POL K7', 'POL K8', 'POL K9', 'POL K10', 'POL K11', 'POL K12', 'POL L1', 'POL L2', 'POL L3', 'POL L4', 'POL L5', 'POL L6', 'POL L7', 'POL L8', 'POL L9', 'POL L10', 'POL L11', 'POL L12', 'EEG M1-Ref-0', 'EEG M2-Ref-0', 'POL M3', 'POL M4', 'POL M5', 'POL M6', 'POL M7', 'POL M8', 'POL EKG', 'EEG F3-Ref-1', 'EEG C3-Ref-1', 'EEG P3-Ref', 'EEG F4-Ref-1', 'EEG C4-Ref-1', 'EEG P4-Ref', 'EEG Fz-Ref', 'EEG Cz-Ref', 'POL RT1', 'POL RT2', 'POL EOGL', 'POL EOGR', 'POL M0', 'EEG M1-Ref-1', 'EEG M2-Ref-1', 'POL 0-0', 'POL 0-1', 'POL 0-2', 'POL 0-3', 'POL 0-4', 'POL 0-5', 'POL 0-6', 'POL 0-7', 'POL 0-8', 'POL 0-9', 'POL 0-10', 'POL 0-11', 'POL 0-12', 'POL 0-13', 'POL 0-14', 'POL 0-15', 'POL 0-16', 'POL 0-17', 'POL 0-18', 'POL 0-19', 'POL 0-20', 'POL 00-0', 'POL 0-21', 'POL 00-1', 'POL 0-22', 'POL O8', 'POL 0-23', 'POL 0-24', 'POL 0-25', 'POL 0-26', 'POL 0-27', 'POL 0-28']\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 13201 samples (6.600 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "(2108086,)\n",
      "(60,)\n",
      "(2108086, 2)\n",
      "(2108086, 2)\n",
      "(2108086,)\n",
      "{'Velocity': [3.4906381523304555, 4.36328529781641, 3.926963175002862, 3.490654268696984, 3.4906552589199564, 3.490658719860428, 4.363260589604258, 3.4906558350548913, 3.4906614130599682, 3.926958764922134, 3.490654847772816, 3.4906597762739606, 3.926973145746016, 4.363292841613368, 3.490637460713927, 3.9269687141670184, 3.490657366834348, 3.4906445882984496, 3.4906537949507577, 4.363294644202568, 4.363282899525869, 3.9269717965872, 3.490630555068893, 3.490650914730594, 3.490655937369964, 3.4906629711558135, 4.363273607420112, 3.4906496687890805, 3.926980642777273, 3.4906575184370467, 3.926945445141619, 4.363268537417032, 3.490622296080892, 3.4906373033989873, 3.490653144293537, 3.4906410247705515, 3.490480786003858, 4.3632473799769045, 3.4907431081571483, 3.926989145072041, 3.490657579350553, 3.9269476555474547, 3.490777911232055, 4.363174866273395, 3.4906141976372425, 3.4907279726208653, 3.490594084388011, 3.4906626190727503, 3.926911112710648, 4.363131426718576, 3.9271860418153035, 3.4905015009735876, 3.4905329571247123, 4.36304568404224, 3.4906186183088392, 3.490648541102991, 4.363433848419252, 3.4907663422708612, 3.9270592752666946, 3.49067042009142], 'n_of_objects': [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], 'trial_cue_per_sec': [0.11287981822529514, 0.0902616880269528, 0.10030985486257296, 0.33804010663925127, 0.2255260918489089, 0.22549706624872498, 0.09028329856387203, 0.11287062419946171, 0.3380518023430266, 0.10027362230164527, 0.33805644316886907, 0.22550147595546619, 0.10031081416831067, 0.09025342986283116, 0.11282898876000715, 0.10026761008490898, 0.3380557956422192, 0.22552894746399174, 0.11283267995506568, 0.09027069031164203, 0.09025722301660127, 0.10029764229438565, 0.11282158743417552, 0.22551262067282202, 0.33812418007046907, 0.22551343446320968, 0.09030373342453092, 0.11285708752677429, 0.10030919676878247, 0.3380682661277129, 0.10030106104588687, 0.0902991876466714, 0.11281828506705859, 0.2255195707972177, 0.33808644498611023, 0.2255322891186182, 0.11285605569529468, 0.09025428717937417, 0.3380583113511182, 0.1002651102712358, 0.11286098657903965, 0.10030248061223336, 0.2254752908758049, 0.09027426529242594, 0.3380746342389946, 0.33810195378582303, 0.11281952679789396, 0.22552180104156958, 0.10027579141180752, 0.09031140137893538, 0.10033518657334599, 0.22559957575470532, 0.1128119079927973, 0.0902725513448627, 0.33803441488928526, 0.11284616917019007, 0.0902436592794149, 0.2254784778141908, 0.10034840230674309, 0.33810207349606874], 'POL K1': [108, 121, 97, 217, 147, 138, 110, 94, 226, 110, 204, 146, 101, 106, 80, 102, 208, 142, 103, 102, 107, 94, 109, 131, 198, 152, 92, 100, 93, 242, 106, 98, 101, 158, 230, 145, 98, 116, 216, 97, 99, 109, 157, 104, 228, 242, 108, 143, 121, 89, 86, 144, 97, 110, 216, 100, 120, 133, 89, 228], 'EEG A1-Ref': [90, 97, 84, 181, 142, 132, 84, 71, 199, 103, 189, 134, 84, 92, 80, 98, 186, 129, 74, 88, 95, 88, 98, 116, 180, 140, 70, 91, 72, 201, 98, 75, 102, 132, 181, 120, 77, 101, 198, 94, 92, 88, 128, 76, 178, 194, 106, 118, 95, 87, 83, 131, 85, 88, 192, 83, 94, 128, 92, 191]}\n"
     ]
    }
   ],
   "source": [
    "sub = 10\n",
    "raw, lfp_theta_filtered, trials_data, event_samples, sfreq = get_subject_data(sub, file_paths, hpc_chan2)\n",
    "print(min(len(event_samples), len(trials_data)))\n",
    "preprocess_data = get_preprocess_data(trials_data,event_samples,lfp_theta_filtered)\n",
    "\n",
    "raw_data = preprocess_data['physilogical_data']\n",
    "timestamps = preprocess_data['timestamps']\n",
    "\n",
    "print(np.shape(raw_data))\n",
    "print(np.shape(timestamps))\n",
    "\n",
    "#Set trial number\n",
    "trial_total_num = min(len(trials_data), len(event_samples))\n",
    "channel_num = np.shape(raw_data)[1]\n",
    "theta_cycle_record = {}\n",
    "theta_cycle_record['Velocity'] = []\n",
    "theta_cycle_record['n_of_objects'] = []\n",
    "theta_cycle_record['trial_cue_per_sec'] = []\n",
    "#get timestamp for trial to start and to end\n",
    "for channel in range(channel_num):\n",
    "    theta_cycle_record[hpc_chan2[sub][channel]] = []\n",
    "    for trial_num in range(trial_total_num):\n",
    "\n",
    "        navi_start = int(event_samples[trial_num][0])\n",
    "        navi_end = int(event_samples[trial_num][1])\n",
    "\n",
    "        #Find the index in the array that match the timestamps\n",
    "        start_index = np.where(timestamps == navi_start)[0][0] if np.any(timestamps == navi_start) else None\n",
    "        end_index = np.where(timestamps == navi_end - 1)[0][0] if np.any(timestamps == navi_end - 1) else None\n",
    "        assert(timestamps[start_index] == navi_start)\n",
    "        physilogical_data_navigation = raw_data[start_index:end_index + 1, channel]\n",
    "        count = 0\n",
    "        index = 0\n",
    "        while index < np.shape(physilogical_data_navigation)[0] - 1:\n",
    "            if physilogical_data_navigation[index] * physilogical_data_navigation[index + 1] < 0:\n",
    "                count += 1\n",
    "                index += 1\n",
    "            elif physilogical_data_navigation[index] * physilogical_data_navigation[index + 1] > 0:\n",
    "                index += 1\n",
    "            else:\n",
    "                temp_index = index + 1\n",
    "                while physilogical_data_navigation[index] * physilogical_data_navigation[temp_index + 1] == 0:\n",
    "                    temp_index += 1\n",
    "                if physilogical_data_navigation[index] * physilogical_data_navigation[temp_index + 1] < 0:\n",
    "                    count += 1\n",
    "                index = temp_index\n",
    "        theta_cycle_record[hpc_chan2[sub][channel]].append(count)\n",
    "\n",
    "for trial_num in range(trial_total_num):\n",
    "    theta_cycle_record['Velocity'].append(trials_data[trial_num]['Velocity'])\n",
    "    theta_cycle_record['n_of_objects'].append(trials_data[trial_num]['n_of_objects'])#? cue density?\n",
    "    theta_cycle_record['trial_cue_per_sec'].append(trials_data[trial_num]['trial_cue_per_sec'])\n",
    "\n",
    "\n",
    "print(theta_cycle_record)\n",
    "pd.DataFrame(theta_cycle_record).to_csv(f\"theta_cycles/theta_cycle_{sub}_{file_paths[sub]['info']['name']}.csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
