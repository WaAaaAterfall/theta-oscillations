{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User settings\n",
    "\n",
    "---\n",
    "\n",
    "1) Keep the file structure like this:\n",
    "\n",
    "    normaliser_data/\n",
    "    \n",
    "        Subject01_YG/\n",
    "                HDF5/\n",
    "                    fp_deepinsight and trained model...\n",
    "                Intermediate_data/ \n",
    "                     intermediate .npy file & results\n",
    "                Plot/\n",
    "                    store the plot results\n",
    "                Recordings/\n",
    "                    ...\n",
    "                VideoGame/\n",
    "                    ...\n",
    "                Info/\n",
    "                    ...\n",
    "                    \n",
    "        Subject02_JY/\n",
    "                HDF5/\n",
    "                    fp_deepinsight and trained model...\n",
    "                Intermediate_data/ \n",
    "                     intermediate .npy file & results\n",
    "                Plot/\n",
    "                    store the plot results\n",
    "                Recordings/\n",
    "                    ...\n",
    "                VideoGame/\n",
    "                    ...\n",
    "                Info/\n",
    "                    ...\n",
    "                    \n",
    "                    \n",
    "2)  Then set the subject number to run this pipelineâ†“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from plotly.offline import iplot\n",
    "import plotly.graph_objs as go\n",
    "from skimage import io\n",
    "\n",
    "import mne\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "import h5py\n",
    "import numpy as np# Functions & Dataset\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import time\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_folder = '/Volumes/t7/dku2023/ieeg/'\n",
    "main_folder = 'F:/dku2023/ieeg/'\n",
    "\n",
    "file_paths = {}\n",
    "\n",
    "\n",
    "file_paths[1] = {}\n",
    "file_paths[1]['folder'] = main_folder+'normaliser_data/Subject01_YG/'\n",
    "file_paths[1]['recordings'] = main_folder+'normaliser_data/Subject01_YG/Recordings/yangge0108_navi.edf'\n",
    "file_paths[1]['ttl']        = main_folder+'normaliser_data/Subject01_YG/Recordings/Subject01_YG_part2_ttlMarkerNew.txt'\n",
    "file_paths[1]['game']       = main_folder+'normaliser_data/Subject01_YG/VideoGame/YG20210108Normaliser_navigation_20210108_142413.txt'\n",
    "file_paths[1]['info'] = {}\n",
    "file_paths[1]['info']['name'] = 'YG'\n",
    "\n",
    "file_paths[2] = {}\n",
    "file_paths[2]['folder'] = main_folder+'normaliser_data/Subject02_JY/'\n",
    "file_paths[2]['recordings'] = main_folder+'normaliser_data/Subject02_JY/Recordings/jinyong0118_navi.edf'\n",
    "file_paths[2]['ttl']        = main_folder+'normaliser_data/Subject02_JY/Recordings/Subject02_JY_ttlMarkerNew.txt'\n",
    "file_paths[2]['game']       = main_folder+'normaliser_data/Subject02_JY/VideoGame/Normaliser_navigation_20210118_144504.txt'\n",
    "file_paths[2]['info'] = {}\n",
    "file_paths[2]['info']['name'] = 'JY'\n",
    "\n",
    "file_paths[3] = {}\n",
    "file_paths[3]['folder'] = main_folder+'normaliser_data/Subject03_LYY/'\n",
    "file_paths[3]['recordings'] = main_folder+'normaliser_data/Subject03_LYY/Recordings/linyiyou031002.edf'\n",
    "file_paths[3]['ttl']        = main_folder+'normaliser_data/Subject03_LYY/Recordings/Subject03_LYY_ttlMarkerNew.txt'\n",
    "file_paths[3]['game']       = main_folder+'normaliser_data/Subject03_LYY/VideoGame/Normaliser_navigation_20210310_171054.txt'\n",
    "file_paths[3]['info'] = {}\n",
    "file_paths[3]['info']['name'] = 'LYY'\n",
    "\n",
    "file_paths[4] = {}\n",
    "file_paths[4]['folder'] = main_folder+'normaliser_data/Subject04_YY/'\n",
    "file_paths[4]['recordings'] = main_folder+'normaliser_data/Subject04_YY/Recordings/yuyue0504.edf'\n",
    "file_paths[4]['ttl']        = main_folder+'normaliser_data/Subject04_YY/Recordings/Subject04_YY_ttlMarkerNew.txt'\n",
    "file_paths[4]['game']       = main_folder+'normaliser_data/Subject04_YY/VideoGame/Normaliser_navigation_20210504_135840.txt'\n",
    "file_paths[4]['info'] = {}\n",
    "file_paths[4]['info']['name'] = 'YY'\n",
    "\n",
    "file_paths[6] = {}\n",
    "file_paths[6]['folder'] = main_folder+'normaliser_data/Subject06_ZQ/'\n",
    "file_paths[6]['recordings'] = main_folder+'normaliser_data/Subject06_ZQ/Recordings/zhengqiao0531.edf'\n",
    "file_paths[6]['ttl']        = main_folder+'normaliser_data/Subject06_ZQ/Recordings/Subject06_ZQ_ttlMarkerNew.txt'\n",
    "file_paths[6]['game']       = main_folder+'normaliser_data/Subject06_ZQ/VideoGame/Normaliser_navigation_20210531_095712Zhengqiao.txt'\n",
    "file_paths[6]['info'] = {}\n",
    "file_paths[6]['info']['name'] = 'ZQ'\n",
    "\n",
    "file_paths[7] = {}\n",
    "file_paths[7]['folder'] = main_folder+'normaliser_data/Subject07_CLC/'\n",
    "file_paths[7]['recordings'] = main_folder+'normaliser_data/Subject07_CLC/Recordings/chenlinchao07233.edf'\n",
    "file_paths[7]['ttl']        = main_folder+'normaliser_data/Subject07_CLC/Recordings/Subject07_CLC_ttlMarkerNew.txt'\n",
    "file_paths[7]['game']       = main_folder+'normaliser_data/Subject07_CLC/VideoGame/chenlinchao_Normaliser_navigation_20210723_123129.txt'\n",
    "file_paths[7]['info'] = {}\n",
    "file_paths[7]['info']['name'] = 'CLC'\n",
    "\n",
    "file_paths[8] = {}\n",
    "file_paths[8]['folder'] = main_folder+'normaliser_data/Subject08_SCM/'\n",
    "file_paths[8]['recordings'] = main_folder+'normaliser_data/Subject08_SCM/Recordings/shenchunmei07301.edf'\n",
    "file_paths[8]['ttl']        = main_folder+'normaliser_data/Subject08_SCM/Recordings/Subject08_SCM_ttlMarkerNew.txt'\n",
    "file_paths[8]['game']       = main_folder+'normaliser_data/Subject08_SCM/VideoGame/scm_Normaliser_navigation_20210730_151846.txt'\n",
    "file_paths[8]['info'] = {}\n",
    "file_paths[8]['info']['name'] = 'SCM'\n",
    "\n",
    "file_paths[9] = {}\n",
    "file_paths[9]['folder'] =main_folder+'normaliser_data/Subject09_LZ/'\n",
    "file_paths[9]['recordings'] = main_folder+'normaliser_data/Subject09_LZ/Recordings/liuzhe08251.edf'\n",
    "file_paths[9]['ttl']        = main_folder+'normaliser_data/Subject09_LZ/Recordings/Subject09_LZ_ttlMarkerNew.txt'\n",
    "file_paths[9]['game']       = main_folder+'normaliser_data/Subject09_LZ/VideoGame/Liuzhe_Normaliser_navigation_20210825_103719.txt'\n",
    "file_paths[9]['info'] = {}\n",
    "file_paths[9]['info']['name'] = 'LZ'\n",
    "\n",
    "file_paths[10] = {}\n",
    "file_paths[10]['folder'] = main_folder+'normaliser_data/Subject10_ZLX/'\n",
    "file_paths[10]['recordings'] = main_folder+'normaliser_data/Subject10_ZLX/Recordings/zhoulongxin09031.edf'\n",
    "file_paths[10]['ttl']        = main_folder+'normaliser_data/Subject10_ZLX/Recordings/Subject10_1_ttlMarkerNew.txt'\n",
    "file_paths[10]['game']       = main_folder+'normaliser_data/Subject10_ZLX/VideoGame/zhoulongxin_Normaliser_navigation_20210903_103923.txt'\n",
    "file_paths[10]['info'] = {}\n",
    "file_paths[10]['info']['name'] = 'ZLX'\n",
    "\n",
    "file_paths[11] = {}\n",
    "file_paths[11]['folder'] = main_folder+'normaliser_data/Subject11_WCF/'\n",
    "file_paths[11]['recordings'] = main_folder+'normaliser_data/Subject10_ZLX/Recordings/wangchunfei0927.edf'\n",
    "file_paths[11]['ttl']        = main_folder+'normaliser_data/Subject10_ZLX/Recordings/Subject11_ttlMarkerNew.txt'\n",
    "file_paths[11]['game']       = main_folder+'normaliser_data/Subject10_ZLX/VideoGame/wangchunfei_Normaliser_navigation_20210927_161155.txt'\n",
    "file_paths[11]['info'] = {}\n",
    "file_paths[11]['info']['name'] = 'ZLX'\n",
    "hpc_chan2 = {}\n",
    "\n",
    "hpc_chan2[1] = ['POL B1', 'POL N1']\n",
    "hpc_chan2[2] = ['POL B1', 'POL D3']\n",
    "hpc_chan2[3] = ['POL E1']\n",
    "hpc_chan2[4] = ['POL I2']\n",
    "hpc_chan2[7] = ['POL I3']\n",
    "hpc_chan2[8] = ['POL J1','EEG C1-Ref']\n",
    "hpc_chan2[9] = ['EEG A1-Ref','POL B2']\n",
    "hpc_chan2[10] = ['POL K1','EEG A1-Ref']\n",
    "\n",
    "### Use this selection for bipolarizing\n",
    "# hpc_chan2[1] = ['POL B1','POL B2']\n",
    "# hpc_chan2[2] = ['POL B1', 'POL D3']\n",
    "# hpc_chan2[3] = ['POL E1','POL E2']\n",
    "# hpc_chan2[4] = ['POL I2','POL I3']\n",
    "# hpc_chan2[7] = ['POL I3', 'POL I4']\n",
    "# hpc_chan2[8] = ['POL J1','POL J2']\n",
    "\n",
    "# deepInsight_encode =  file_paths[sub]['folder'] + 'HDF5/deepInsight_encode.h5' \n",
    "# fp_plot = file_paths[sub]['folder'] + 'Plot/'\n",
    "# fp_data = file_paths[sub]['folder'] + 'Intermediate_data/'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## necessary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and parsing each trial video game feature\n",
    "def structure_gamelog(gamelog):\n",
    "\n",
    "    trials_data = {}\n",
    "\n",
    "    reading_navigation_positions = False\n",
    "\n",
    "    for line in gamelog:\n",
    "\n",
    "\n",
    "        if line.startswith('Trial ended'):\n",
    "            trials_data[trial_n]['Trial_ended_time'] = float(line.split(' ')[-1]) \n",
    "\n",
    "            trial_duration = trials_data[trial_n]['Trial_ended_time'] - trials_data[trial_n]['Trial_start_time']\n",
    "            trials_data[trial_n]['trial_duration'] = trial_duration\n",
    "            trials_data[trial_n]['n_of_objects'] = len(trials_data[trial_n]['Objects_location'])\n",
    "\n",
    "            trials_data[trial_n]['Navigation'] = np.array(trials_data[trial_n]['Navigation'])\n",
    "            \n",
    "            ### Compute velocity from position (navigation) coordinates\n",
    "            trial_duration = trials_data[trial_n]['Navigation'][:,0][-1] - trials_data[trial_n]['Navigation'][:,0][0]\n",
    "            # trial_distance in meters\n",
    "            trial_distance = np.sum(np.abs(np.diff(trials_data[trial_n]['Navigation'][:,1] +1j* trials_data[trial_n]['Navigation'][:,2])))\n",
    "            trials_data[trial_n]['Velocity'] = trial_distance/trial_duration\n",
    "            \n",
    "            \n",
    "            trials_data[trial_n]['Objects_location'] = np.array(trials_data[trial_n]['Objects_location'])\n",
    "\n",
    "            # trial_distance in angles\n",
    "            trial_distance = np.unwrap( np.angle( trials_data[trial_n]['Navigation'][:,1] +1j* trials_data[trial_n]['Navigation'][:,2] ) )\n",
    "            trial_distance = trial_distance[-1] - trial_distance[0]\n",
    "            trials_data[trial_n]['Trial_distance'] = trial_distance\n",
    "            trials_data[trial_n]['Velocity_deg_per_sec'] = trial_distance / trial_duration\n",
    "\n",
    "            ### cue/sec needs to get how many laps were performed and ajust it to the number of items per every lap (2pi)\n",
    "            this_trial_crossed_objects = trial_distance  * trials_data[trial_n]['n_of_objects'] / np.pi*2\n",
    "            trials_data[trial_n]['num_cue'] = this_trial_crossed_objects\n",
    "            trial_cue_per_sec = trials_data[trial_n]['trial_duration'] / this_trial_crossed_objects\n",
    "            trials_data[trial_n]['trial_cue_per_sec'] = trial_cue_per_sec\n",
    "\n",
    "\n",
    "            reading_navigation_positions = False\n",
    "\n",
    "\n",
    "        if reading_navigation_positions==False:\n",
    "\n",
    "            if line.startswith('Trial number'): \n",
    "                trial_n = int(line.split(': ')[1][:-1])\n",
    "                trials_data[trial_n] = {}\n",
    "            if line.startswith('Speed'): \n",
    "                trials_data[trial_n]['Speed'] = float(line.split('Speed: ')[1][:-1])\n",
    "            if line.startswith('Ring_size'): \n",
    "                trials_data[trial_n]['Ring_size'] = float(line.split('Ring_size: ')[1][:-1])\n",
    "\n",
    "            if line.startswith('Objects location'):\n",
    "                ### actualItem  +\" \"+ itemX +\" \"+ itemZ +\" \"+ itemAngle\n",
    "                trials_data[trial_n]['Objects_location'] = []\n",
    "            if line.startswith('Item:'):\n",
    "                trials_data[trial_n]['Objects_location'].append( np.array(line.split('Item: ')[1][:-1].split(' ')).astype(float) )\n",
    "\n",
    "            if line.startswith('Trial start'):\n",
    "                trials_data[trial_n]['Navigation'] = []\n",
    "                reading_navigation_positions = True\n",
    "                trials_data[trial_n]['Trial_start_time'] = float(line.split(' ')[-1]) \n",
    "\n",
    "\n",
    "            if line.startswith('Question onset'):\n",
    "                trials_data[trial_n]['Testing'] = {}\n",
    "                trials_data[trial_n]['Testing']['Question_onset'] = float(line.split('Question onset ')[1][:-1])\n",
    "\n",
    "            if line.startswith('Testing'):            \n",
    "                tmp_line = line[:-1].split(' ')\n",
    "                trials_data[trial_n]['Testing']['response_time'] = float(tmp_line[1])\n",
    "                trials_data[trial_n]['Testing']['cued_object'] = int(tmp_line[3])\n",
    "                trials_data[trial_n]['Testing']['option_1'] = int(tmp_line[5])\n",
    "                trials_data[trial_n]['Testing']['option_2'] = int(tmp_line[7])\n",
    "                trials_data[trial_n]['Testing']['asnwered_object'] = int(tmp_line[9])\n",
    "                trials_data[trial_n]['Testing']['asnwered_key'] = tmp_line[11]\n",
    "\n",
    "        elif reading_navigation_positions==True:\n",
    "            trials_data[trial_n]['Navigation'].append( np.array(line[:-1].split(' ')).astype(float) )\n",
    "\n",
    "    return trials_data\n",
    "\n",
    "\n",
    "def interp_f(behavioural_signal, lfp_size):\n",
    "    n_samples = len(behavioural_signal)\n",
    "    x = np.linspace(0, n_samples, num=n_samples, endpoint=True)\n",
    "    interpolate_f = interp1d(x, behavioural_signal, kind='linear')\n",
    "    new_sampling_space = np.linspace(0, n_samples, num=lfp_size, endpoint=True)\n",
    "    return interpolate_f(new_sampling_space)\n",
    "\n",
    "\n",
    "def get_behavioral_position(trials_data, trial_number):\n",
    "    position_array = []\n",
    "    for count in range(len(trials_data[trial_number]['Navigation'])):\n",
    "        time = trials_data[trial_number]['Navigation'][count][0]\n",
    "        x = trials_data[trial_number]['Navigation'][count][1]\n",
    "        y = trials_data[trial_number]['Navigation'][count][2]\n",
    "        position_array.append([trial_number, time, x, y])\n",
    "        \n",
    "    return np.array(position_array)\n",
    "\n",
    "\n",
    "'''\n",
    "Extract navigation data from recording txt file\n",
    "Return:\n",
    "    data selected from hippocampol channel, \n",
    "    lfp_theta_filtered, applied norch and theta filter on raw data\n",
    "    trials_data, extract from game log, see def struct_gamelog\n",
    "    event_samples, TTL information and index for navigation start, end...etc\n",
    "    int(raw.info['sfreq']) s_frequency info\n",
    "'''\n",
    "def get_subject_data(sub, file_paths, hpc_chan2):\n",
    "\n",
    "    # Load brain recordings\n",
    "    raw = mne.io.read_raw_edf(file_paths[sub]['recordings'])\n",
    "    print(\"all channel name:\", raw.ch_names)\n",
    "    #print(np.shape(raw))\n",
    "    # Load TTL events\n",
    "    TTL = pd.read_csv(file_paths[sub]['ttl'],\n",
    "                      sep=' ',\n",
    "                      names=['time', 'type', 'n'])\n",
    "    #print(TTL)\n",
    "\n",
    "    # Get hippocampal channels of this subject\n",
    "    sub_hpc_chans = hpc_chan2[sub]\n",
    "    data = raw.get_data(picks=sub_hpc_chans)\n",
    "\n",
    "    # Load videoGame data and structure it by trials\n",
    "    gamelog = []\n",
    "    with open(file_paths[sub]['game'], 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            gamelog.append(line)\n",
    "    trials_data = structure_gamelog(gamelog)\n",
    "\n",
    "    ### Load the signal\n",
    "    # Here loading 2 signals in the Amygdala. This will be specific for each patient.\n",
    "    lfps = raw.get_data(picks=sub_hpc_chans)\n",
    "\n",
    "    ## Notch is done to remove the noise from the power line in the building. Since China operates on a 220V voltage and 50Hz and remove the 50Hz and its harmonics (100, 150, etc) to the signal.\n",
    "    lfp_bp_notch = mne.filter.notch_filter(lfps,\n",
    "                                           raw.info['sfreq'],\n",
    "                                           [50., 100., 150., 200.],\n",
    "                                           notch_widths=.1)\n",
    "#   lfp_bp_notch = lfp_bp_notch[0] - lfp_bp_notch[1]\n",
    "    low_freq = 2\n",
    "    high_freq = 10\n",
    "\n",
    "    lfp_theta_filtered = mne.filter.filter_data(lfp_bp_notch, int(raw.info['sfreq']), low_freq, high_freq, verbose=False )\n",
    "\n",
    "    ### TTL markers\n",
    "    event_samples = np.vstack((\n",
    "        TTL[TTL['type'] == 2]['time'].values,\n",
    "        TTL[TTL['type'] == 3]['time'].values,\n",
    "        TTL[TTL['type'] == 4]['time'].values,\n",
    "        TTL[TTL['type'] == 5]['time'].values,\n",
    "    )).T\n",
    "\n",
    "    return data, lfp_theta_filtered, trials_data, event_samples, int(raw.info['sfreq'])\n",
    "\n",
    "\n",
    "'''\n",
    "Deal with ieeg signal data\n",
    "Return: \n",
    "a dict with essential information\n",
    "physilogical data: a list of the ieeg signal between navigation for all trials\n",
    "timestamps: a list of index matching physilogical data\n",
    "position_2d: coordinate..ish matching each timestamp\n",
    "event_marker: \n",
    "'''\n",
    "def get_preprocess_data(trials_data,markers,physilogical_data,start_end_indice=[0,1],test=False): #trials, event_sample, notch_filtered_data\n",
    "    \n",
    "    '''\n",
    "    start_end_indice:\n",
    "        markers[:][0] the start of one trial\n",
    "        markers[:][1] the end of one trial\n",
    "        markers[:][2] the onset of the testing question\n",
    "        markers[:][3] the onset of response\n",
    "    test: \n",
    "        True: decode the recall part, no real output(position)\n",
    "    '''\n",
    "    physilogical_data_navi= {}\n",
    "\n",
    "    for chan in range(physilogical_data.shape[0]):\n",
    "        \n",
    "        for trial_num in range(min(len(trials_data), len(markers))):  \n",
    "            behavioural_signal = get_behavioral_position(trials_data, trial_num)\n",
    "            navi_start = int(markers[trial_num][start_end_indice[0]])\n",
    "            navi_stop = int(markers[trial_num][start_end_indice[1]])\n",
    "            lfp_size = abs(navi_stop - navi_start)\n",
    "            \n",
    "            if (chan == 0) & (trial_num == 0):\n",
    "                start_array = np.array([lfp_size])\n",
    "                timestamps = np.linspace(navi_start,navi_stop-1,lfp_size, dtype=int)\n",
    "                if test == False :\n",
    "                    position_2d = np.vstack(( interp_f(behavioural_signal.T[2], lfp_size) , interp_f(behavioural_signal.T[3], lfp_size)))\n",
    "                \n",
    "            if (chan == 0) & (trial_num > 0):\n",
    "                start_array = np.hstack((start_array,np.array([int(start_array[trial_num-1])+lfp_size])))\n",
    "                timestamps = np.hstack(( timestamps, np.linspace(navi_start,navi_stop-1,lfp_size, dtype=int) ))\n",
    "                if test == False :\n",
    "                    position_2d = np.hstack((position_2d, np.vstack(( interp_f(behavioural_signal.T[2], lfp_size) , interp_f(behavioural_signal.T[3], lfp_size)))  ))\n",
    "                \n",
    "            if trial_num == 0:\n",
    "                physilogical_data_navi[chan]= physilogical_data[chan][navi_start:navi_stop]\n",
    "                \n",
    "            if trial_num > 0:\n",
    "                physilogical_data_navi[chan]  = np.hstack((physilogical_data_navi[chan], physilogical_data[chan][navi_start:navi_stop] ))\n",
    "    \n",
    "    print(np.shape(timestamps))\n",
    "    print(np.shape(start_array))\n",
    "    print(np.shape(np.array([physilogical_data_navi[i] for i in range(len(physilogical_data_navi))]).T))\n",
    "    if test == True :\n",
    "        return {\n",
    "            'physilogical_data': np.array([physilogical_data_navi[i] for i in range(len(physilogical_data_navi))]).T,\n",
    "            'timestamps': timestamps,\n",
    "            'event_marker_each_trial': start_array\n",
    "        }\n",
    "    if test == False :               \n",
    "        return {\n",
    "            'physilogical_data': np.array([physilogical_data_navi[i] for i in range(len(physilogical_data_navi))]).T,\n",
    "            'timestamps': timestamps,\n",
    "            'position_2d': position_2d,\n",
    "            'event_marker_each_trial': start_array\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Number of Theta Cycles from physilogical data nad event sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from F:\\dku2023\\ieeg\\normaliser_data\\Subject08_SCM\\Recordings\\shenchunmei07301.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\River\\AppData\\Local\\Temp\\ipykernel_12092\\2570443818.py:117: RuntimeWarning:\n",
      "\n",
      "Channel names are not unique, found duplicates for: {'POL 0'}. Applying running numbers for duplicates.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all channel name: ['EEG A1-Ref', 'EEG A2-Ref', 'POL A3', 'POL A4', 'POL A5', 'POL A6', 'POL A7', 'POL A8', 'POL A9', 'POL A10', 'POL A13', 'POL A14', 'POL B1', 'POL B2', 'POL B3', 'POL B4', 'POL B5', 'POL B6', 'POL B7', 'POL E', 'POL B8', 'POL B9', 'POL A11', 'POL A12', 'POL B10', 'POL B11', 'POL B12', 'POL B13', 'POL B14', 'EEG C1-Ref', 'EEG C2-Ref', 'EEG C3-Ref', 'EEG C4-Ref', 'EEG C5-Ref', 'EEG C6-Ref', 'POL C7', 'POL C8', 'POL DC01', 'POL DC02', 'POL DC03', 'POL DC04', 'POL DC05', 'POL DC06', 'POL DC07', 'POL DC08', 'POL DC09', 'POL DC10', 'POL DC11', 'POL DC12', 'POL DC13', 'POL DC14', 'POL DC15', 'POL DC16', 'POL C9', 'POL C10', 'POL C11', 'POL C12', 'POL C13', 'POL C14', 'POL D1', 'POL D2', 'POL D3', 'POL D4', 'POL D5', 'POL D6', 'POL D7', 'POL D8', 'POL D9', 'POL D10', 'POL D11', 'POL D12', 'POL E1', 'POL E2', 'POL E3', 'POL E4', 'POL E5', 'POL E6', 'POL E7', 'POL E8', 'POL E9', 'POL E10', 'POL E11', 'POL E12', 'POL E13', 'POL E14', 'EEG F1-Ref', 'EEG F2-Ref', 'EEG F3-Ref', 'EEG F4-Ref', 'EEG F5-Ref', 'EEG F6-Ref', 'EEG F7-Ref', 'EEG F8-Ref', 'POL G1', 'POL G2', 'POL G3', 'POL G4', 'POL G5', 'POL G6', 'POL G7', 'POL G8', 'POL H1', 'POL H2', 'POL H3', 'POL H4', 'POL H5', 'POL H6', 'POL H7', 'POL H8', 'POL H9', 'POL H10', 'POL H11', 'POL H12', 'POL H13', 'POL H14', 'POL I1', 'POL I2', 'POL I3', 'POL I4', 'POL I5', 'POL I6', 'POL I7', 'POL I8', 'POL I9', 'POL I10', 'POL I11', 'POL I12', 'POL J1', 'POL J2', 'POL J3', 'POL J4', 'POL J5', 'POL J6', 'POL J7', 'POL J8', 'POL J9', 'POL J10', 'POL J11', 'POL J12', 'POL EKG', 'POL 0-0', 'POL 0-1', 'POL 0-2', 'POL 0-3', 'POL 0-4']\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 13201 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n",
      "c:\\Users\\River\\anaconda3\\envs\\mne\\lib\\site-packages\\mne\\filter.py:312: DeprecationWarning:\n",
      "\n",
      "Keyword argument 'nyq' is deprecated in favour of 'fs' and will be removed in SciPy 1.12.0.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "(2109761,)\n",
      "(60,)\n",
      "(1291115, 2)\n",
      "(2109761,)\n",
      "(1291115, 2)\n",
      "got one 0 24233 0\n",
      "got one 24234 53496 1\n",
      "got one 53497 79272 2\n",
      "got one 79273 136982 3\n",
      "got one 136983 174769 4\n",
      "got one 174770 213644 5\n",
      "got one 213645 239420 6\n",
      "got one 239421 264033 7\n",
      "got one 264034 320280 8\n",
      "got one 320281 350173 9\n",
      "got one 350174 406606 10\n",
      "got one 406607 445357 11\n",
      "got one 445358 471266 12\n",
      "got one 471267 499443 13\n",
      "got one 499444 525100 14\n",
      "got one 525101 554693 15\n",
      "got one 554694 610919 16\n",
      "got one 610920 649587 17\n",
      "got one 649588 676386 18\n",
      "got one 676387 703034 19\n",
      "got one 703035 731991 20\n",
      "got one 731992 757661 21\n",
      "got one 757662 786382 22\n",
      "got one 786383 825275 23\n",
      "got one 825276 882054 24\n",
      "got one 882055 920926 25\n",
      "got one 920927 945018 26\n",
      "got one 945019 970224 27\n",
      "got one 970225 995778 28\n",
      "got one 995779 1052063 29\n",
      "got one 1052064 1079077 30\n",
      "got one 1079078 1103312 31\n",
      "got one 1103313 1132472 32\n",
      "got one 1132473 1171006 33\n",
      "got one 1171007 1228425 34\n",
      "got one 1228426 1265388 35\n",
      "got one 1265389 1291114 36\n",
      "got one 1291115 1320306 37\n",
      "got one 1320307 1376392 38\n",
      "got one 1376393 1405818 39\n",
      "got one 1405819 1431412 40\n",
      "got one 1431413 1458638 41\n",
      "got one 1458639 1496896 42\n",
      "got one 1496897 1522122 43\n",
      "got one 1522123 1579006 44\n",
      "got one 1579007 1636756 45\n",
      "got one 1636757 1666548 46\n",
      "got one 1666549 1704538 47\n",
      "got one 1704539 1734496 48\n",
      "got one 1734497 1758522 49\n",
      "got one 1758523 1783250 50\n",
      "got one 1783251 1820740 51\n",
      "got one 1820741 1848532 52\n",
      "got one 1848533 1876190 53\n",
      "got one 1876191 1932242 54\n",
      "got one 1932243 1959602 55\n",
      "got one 1959603 1989592 56\n",
      "got one 1989593 2028582 57\n",
      "got one 2028583 2052608 58\n",
      "got one 2052609 2109760 59\n",
      "got one 0 24233 0\n",
      "got one 24234 53496 1\n",
      "got one 53497 79272 2\n",
      "got one 79273 136982 3\n",
      "got one 136983 174769 4\n",
      "got one 174770 213644 5\n",
      "got one 213645 239420 6\n",
      "got one 239421 264033 7\n",
      "got one 264034 320280 8\n",
      "got one 320281 350173 9\n",
      "got one 350174 406606 10\n",
      "got one 406607 445357 11\n",
      "got one 445358 471266 12\n",
      "got one 471267 499443 13\n",
      "got one 499444 525100 14\n",
      "got one 525101 554693 15\n",
      "got one 554694 610919 16\n",
      "got one 610920 649587 17\n",
      "got one 649588 676386 18\n",
      "got one 676387 703034 19\n",
      "got one 703035 731991 20\n",
      "got one 731992 757661 21\n",
      "got one 757662 786382 22\n",
      "got one 786383 825275 23\n",
      "got one 825276 882054 24\n",
      "got one 882055 920926 25\n",
      "got one 920927 945018 26\n",
      "got one 945019 970224 27\n",
      "got one 970225 995778 28\n",
      "got one 995779 1052063 29\n",
      "got one 1052064 1079077 30\n",
      "got one 1079078 1103312 31\n",
      "got one 1103313 1132472 32\n",
      "got one 1132473 1171006 33\n",
      "got one 1171007 1228425 34\n",
      "got one 1228426 1265388 35\n",
      "got one 1265389 1291114 36\n",
      "got one 1291115 1320306 37\n",
      "got one 1320307 1376392 38\n",
      "got one 1376393 1405818 39\n",
      "got one 1405819 1431412 40\n",
      "got one 1431413 1458638 41\n",
      "got one 1458639 1496896 42\n",
      "got one 1496897 1522122 43\n",
      "got one 1522123 1579006 44\n",
      "got one 1579007 1636756 45\n",
      "got one 1636757 1666548 46\n",
      "got one 1666549 1704538 47\n",
      "got one 1704539 1734496 48\n",
      "got one 1734497 1758522 49\n",
      "got one 1758523 1783250 50\n",
      "got one 1783251 1820740 51\n",
      "got one 1820741 1848532 52\n",
      "got one 1848533 1876190 53\n",
      "got one 1876191 1932242 54\n",
      "got one 1932243 1959602 55\n",
      "got one 1959603 1989592 56\n",
      "got one 1989593 2028582 57\n",
      "got one 2028583 2052608 58\n",
      "got one 2052609 2109760 59\n"
     ]
    }
   ],
   "source": [
    "sub = 8\n",
    "raw, lfp_theta_filtered, trials_data, event_samples, sfreq = get_subject_data(sub, file_paths, hpc_chan2)\n",
    "print(min(len(event_samples), len(trials_data)))\n",
    "preprocess_data = get_preprocess_data(trials_data,event_samples,lfp_theta_filtered)\n",
    "\n",
    "raw_data = preprocess_data['physilogical_data']\n",
    "timestamps = preprocess_data['timestamps']\n",
    "# plt.title('theta_cycle')\n",
    "# y_axis = raw_data[:, 0]\n",
    "# p1 = plt.plot(y_axis, marker='o', color = 'green')\n",
    "\n",
    "print(np.shape(timestamps))\n",
    "print(np.shape(raw_data))\n",
    "\n",
    "#Set trial number\n",
    "trial_total_num = min(len(trials_data), len(event_samples))\n",
    "channel_num = np.shape(raw_data)[1]\n",
    "theta_cycle_record = {}\n",
    "theta_cycle_record['Velocity'] = []\n",
    "theta_cycle_record['num_cue'] = []\n",
    "theta_cycle_record['trial_cue_per_sec'] = []\n",
    "#get timestamp for trial to start and to end\n",
    "for channel in range(channel_num):\n",
    "    theta_cycle_record[hpc_chan2[sub][channel]] = []\n",
    "    i = 0\n",
    "    for trial_num in range(trial_total_num):\n",
    "\n",
    "        navi_start = int(event_samples[trial_num][0])\n",
    "        navi_end = int(event_samples[trial_num][1])\n",
    "\n",
    "        #Find the index in the preprocess signal array that match the timestamps\n",
    "        start_index = np.where(timestamps == navi_start)[0][0] if np.any(timestamps == navi_start) else None\n",
    "        end_index = np.where(timestamps == navi_end - 1)[0][0] if np.any(timestamps == navi_end - 1) else None\n",
    "        print(\"got one\", start_index, end_index, i)\n",
    "        i += 1\n",
    "        assert(timestamps[start_index] == navi_start)\n",
    "        physilogical_data_navigation = raw_data[start_index:end_index + 1, channel]\n",
    "        count = 0\n",
    "        index = 0\n",
    "        while index < np.shape(physilogical_data_navigation)[0] - 1:\n",
    "            # if the theta signal across 0\n",
    "            if physilogical_data_navigation[index] * physilogical_data_navigation[index + 1] < 0:\n",
    "                count += 1\n",
    "                index += 1\n",
    "            # if the signal does not across 0\n",
    "            elif physilogical_data_navigation[index] * physilogical_data_navigation[index + 1] > 0:\n",
    "                index += 1\n",
    "            # if signal is 0\n",
    "            else:\n",
    "                temp_index = index + 1\n",
    "                while physilogical_data_navigation[index] * physilogical_data_navigation[temp_index + 1] == 0:\n",
    "                    temp_index += 1\n",
    "                if physilogical_data_navigation[index] * physilogical_data_navigation[temp_index + 1] < 0:\n",
    "                    count += 1\n",
    "                index = temp_index\n",
    "        theta_cycle_record[hpc_chan2[sub][channel]].append(count)\n",
    "\n",
    "for trial_num in range(trial_total_num):\n",
    "    theta_cycle_record['Velocity'].append(trials_data[trial_num]['Velocity_deg_per_sec'])\n",
    "    theta_cycle_record['num_cue'].append(trials_data[trial_num]['num_cue'])#? cue density?\n",
    "    theta_cycle_record['trial_cue_per_sec'].append(trials_data[trial_num]['trial_cue_per_sec'])\n",
    "\n",
    "\n",
    "# print(theta_cycle_record)\n",
    "# pd.DataFrame(theta_cycle_record).to_csv(f\"theta_cycles/theta_cycle_{sub}_{file_paths[sub]['info']['name']}.csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('theta_circle')\n",
    "theta_cycle_record = pd.read_csv(f\"theta_circles/theta_circle_{sub}_{file_paths[sub]['info']['name']}.csv\").to_numpy()\n",
    "ordered_record = theta_cycle_record[theta_cycle_record[:, 2].argsort()]\n",
    "x_axis = ordered_record[:,2]\n",
    "y_axis = ordered_record[:,3]\n",
    "p1 = plt.plot(x_axis, y_axis, marker='o', label=hpc_chan2[sub][0], color = 'green')\n",
    "plt.xlabel('cue_per_sec')\n",
    "plt.ylabel('number_of_circles')\n",
    "plt.legend()\n",
    "plt.savefig(f\"C:/Users/River/23summer/dku/ieeg/theta_circle_graph_cue_per_trial/theta_cycle_{sub}_{file_paths[sub]['info']['name']}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('theta_circle')\n",
    "theta_cycle_record = pd.read_csv(f\"theta_cycles/theta_cycle_{sub}_{file_paths[sub]['info']['name']}.csv\").to_numpy()\n",
    "ordered_record = theta_cycle_record[theta_cycle_record[:, 2].argsort()]\n",
    "x_axis = ordered_record[:,2]\n",
    "y_axis = ordered_record[:,3]\n",
    "y_axis2 = ordered_record[:,4]\n",
    "p1 = plt.plot(x_axis, y_axis, marker='o', label=hpc_chan2[sub][0], color = 'green')\n",
    "plt.xlabel('cur_per_sec')\n",
    "plt.ylabel('number_of_cycles')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "p2 = plt.plot(x_axis, y_axis2, marker='o', label=hpc_chan2[sub][1], color = 'red')\n",
    "plt.xlabel('cur_per_sec')\n",
    "plt.ylabel('number_of_cycles')\n",
    "plt.legend()\n",
    "plt.savefig(f\"C:/Users/River/23summer/dku/ieeg/theta_cycle_graph_cue_per_trial/theta_cycle_{sub}_{file_paths[sub]['info']['name']}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
