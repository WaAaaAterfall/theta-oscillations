{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User settings\n",
    "\n",
    "---\n",
    "\n",
    "1) Keep the file structure like this:\n",
    "\n",
    "    normaliser_data/\n",
    "    \n",
    "        Subject01_YG/\n",
    "                HDF5/\n",
    "                    fp_deepinsight and trained model...\n",
    "                Intermediate_data/ \n",
    "                     intermediate .npy file & results\n",
    "                Plot/\n",
    "                    store the plot results\n",
    "                Recordings/\n",
    "                    ...\n",
    "                VideoGame/\n",
    "                    ...\n",
    "                Info/\n",
    "                    ...\n",
    "                    \n",
    "        Subject02_JY/\n",
    "                HDF5/\n",
    "                    fp_deepinsight and trained model...\n",
    "                Intermediate_data/ \n",
    "                     intermediate .npy file & results\n",
    "                Plot/\n",
    "                    store the plot results\n",
    "                Recordings/\n",
    "                    ...\n",
    "                VideoGame/\n",
    "                    ...\n",
    "                Info/\n",
    "                    ...\n",
    "                    \n",
    "                    \n",
    "2)  Then set the subject number to run this pipelineâ†“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from plotly.offline import iplot\n",
    "import plotly.graph_objs as go\n",
    "from skimage import io\n",
    "\n",
    "import mne\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "import h5py\n",
    "import numpy as np# Functions & Dataset\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import time\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_folder = '/Volumes/t7/dku2023/ieeg/'\n",
    "main_folder = 'F:/dku2023/ieeg/'\n",
    "\n",
    "file_paths = {}\n",
    "\n",
    "\n",
    "file_paths[1] = {}\n",
    "file_paths[1]['folder'] = main_folder+'normaliser_data/Subject01_YG/'\n",
    "file_paths[1]['recordings'] = main_folder+'normaliser_data/Subject01_YG/Recordings/yangge0108_navi.edf'\n",
    "file_paths[1]['ttl']        = main_folder+'normaliser_data/Subject01_YG/Recordings/Subject01_YG_part2_ttlMarkerNew.txt'\n",
    "file_paths[1]['game']       = main_folder+'normaliser_data/Subject01_YG/VideoGame/YG20210108Normaliser_navigation_20210108_142413.txt'\n",
    "file_paths[1]['info'] = {}\n",
    "file_paths[1]['info']['name'] = 'YG'\n",
    "\n",
    "file_paths[2] = {}\n",
    "file_paths[2]['folder'] = main_folder+'normaliser_data/Subject02_JY/'\n",
    "file_paths[2]['recordings'] = main_folder+'normaliser_data/Subject02_JY/Recordings/jinyong0118_navi.edf'\n",
    "file_paths[2]['ttl']        = main_folder+'normaliser_data/Subject02_JY/Recordings/Subject02_JY_ttlMarkerNew.txt'\n",
    "file_paths[2]['game']       = main_folder+'normaliser_data/Subject02_JY/VideoGame/Normaliser_navigation_20210118_144504.txt'\n",
    "file_paths[2]['info'] = {}\n",
    "file_paths[2]['info']['name'] = 'JY'\n",
    "\n",
    "file_paths[3] = {}\n",
    "file_paths[3]['folder'] = main_folder+'normaliser_data/Subject03_LYY/'\n",
    "file_paths[3]['recordings'] = main_folder+'normaliser_data/Subject03_LYY/Recordings/linyiyou031002.edf'\n",
    "file_paths[3]['ttl']        = main_folder+'normaliser_data/Subject03_LYY/Recordings/Subject03_LYY_ttlMarkerNew.txt'\n",
    "file_paths[3]['game']       = main_folder+'normaliser_data/Subject03_LYY/VideoGame/Normaliser_navigation_20210310_171054.txt'\n",
    "file_paths[3]['info'] = {}\n",
    "file_paths[3]['info']['name'] = 'LYY'\n",
    "\n",
    "file_paths[4] = {}\n",
    "file_paths[4]['folder'] = main_folder+'normaliser_data/Subject04_YY/'\n",
    "file_paths[4]['recordings'] = main_folder+'normaliser_data/Subject04_YY/Recordings/yuyue0504.edf'\n",
    "file_paths[4]['ttl']        = main_folder+'normaliser_data/Subject04_YY/Recordings/Subject04_YY_ttlMarkerNew.txt'\n",
    "file_paths[4]['game']       = main_folder+'normaliser_data/Subject04_YY/VideoGame/Normaliser_navigation_20210504_135840.txt'\n",
    "file_paths[4]['info'] = {}\n",
    "file_paths[4]['info']['name'] = 'YY'\n",
    "\n",
    "file_paths[6] = {}\n",
    "file_paths[6]['folder'] = main_folder+'normaliser_data/Subject06_ZQ/'\n",
    "file_paths[6]['recordings'] = main_folder+'normaliser_data/Subject06_ZQ/Recordings/zhengqiao0531.edf'\n",
    "file_paths[6]['ttl']        = main_folder+'normaliser_data/Subject06_ZQ/Recordings/Subject06_ZQ_ttlMarkerNew.txt'\n",
    "file_paths[6]['game']       = main_folder+'normaliser_data/Subject06_ZQ/VideoGame/Normaliser_navigation_20210531_095712Zhengqiao.txt'\n",
    "file_paths[6]['info'] = {}\n",
    "file_paths[6]['info']['name'] = 'ZQ'\n",
    "\n",
    "file_paths[7] = {}\n",
    "file_paths[7]['folder'] = main_folder+'normaliser_data/Subject07_CLC/'\n",
    "file_paths[7]['recordings'] = main_folder+'normaliser_data/Subject07_CLC/Recordings/chenlinchao07233.edf'\n",
    "file_paths[7]['ttl']        = main_folder+'normaliser_data/Subject07_CLC/Recordings/Subject07_CLC_ttlMarkerNew.txt'\n",
    "file_paths[7]['game']       = main_folder+'normaliser_data/Subject07_CLC/VideoGame/chenlinchao_Normaliser_navigation_20210723_123129.txt'\n",
    "file_paths[7]['info'] = {}\n",
    "file_paths[7]['info']['name'] = 'CLC'\n",
    "\n",
    "file_paths[8] = {}\n",
    "file_paths[8]['folder'] = main_folder+'normaliser_data/Subject08_SCM/'\n",
    "file_paths[8]['recordings'] = main_folder+'normaliser_data/Subject08_SCM/Recordings/shenchunmei07301.edf'\n",
    "file_paths[8]['ttl']        = main_folder+'normaliser_data/Subject08_SCM/Recordings/Subject08_SCM_ttlMarkerNew.txt'\n",
    "file_paths[8]['game']       = main_folder+'normaliser_data/Subject08_SCM/VideoGame/scm_Normaliser_navigation_20210730_151846.txt'\n",
    "file_paths[8]['info'] = {}\n",
    "file_paths[8]['info']['name'] = 'SCM'\n",
    "\n",
    "file_paths[9] = {}\n",
    "file_paths[9]['folder'] =main_folder+'normaliser_data/Subject09_LZ/'\n",
    "file_paths[9]['recordings'] = main_folder+'normaliser_data/Subject09_LZ/Recordings/liuzhe08251.edf'\n",
    "file_paths[9]['ttl']        = main_folder+'normaliser_data/Subject09_LZ/Recordings/Subject09_LZ_ttlMarkerNew.txt'\n",
    "file_paths[9]['game']       = main_folder+'normaliser_data/Subject09_LZ/VideoGame/Liuzhe_Normaliser_navigation_20210825_103719.txt'\n",
    "file_paths[9]['info'] = {}\n",
    "file_paths[9]['info']['name'] = 'LZ'\n",
    "\n",
    "file_paths[10] = {}\n",
    "file_paths[10]['folder'] = main_folder+'normaliser_data/Subject10_ZLX/'\n",
    "file_paths[10]['recordings'] = main_folder+'normaliser_data/Subject10_ZLX/Recordings/zhoulongxin09031.edf'\n",
    "file_paths[10]['ttl']        = main_folder+'normaliser_data/Subject10_ZLX/Recordings/Subject10_1_ttlMarkerNew.txt'\n",
    "file_paths[10]['game']       = main_folder+'normaliser_data/Subject10_ZLX/VideoGame/zhoulongxin_Normaliser_navigation_20210903_103923.txt'\n",
    "file_paths[10]['info'] = {}\n",
    "file_paths[10]['info']['name'] = 'ZLX'\n",
    "\n",
    "file_paths[11] = {}\n",
    "file_paths[11]['folder'] = main_folder+'normaliser_data/Subject11_WCF/'\n",
    "file_paths[11]['recordings'] = main_folder+'normaliser_data/Subject10_ZLX/Recordings/wangchunfei0927.edf'\n",
    "file_paths[11]['ttl']        = main_folder+'normaliser_data/Subject10_ZLX/Recordings/Subject11_ttlMarkerNew.txt'\n",
    "file_paths[11]['game']       = main_folder+'normaliser_data/Subject10_ZLX/VideoGame/wangchunfei_Normaliser_navigation_20210927_161155.txt'\n",
    "file_paths[11]['info'] = {}\n",
    "file_paths[11]['info']['name'] = 'ZLX'\n",
    "hpc_chan2 = {}\n",
    "\n",
    "hpc_chan2[1] = ['EEG A1-Ref','POL B1', 'POL B2', 'POL B3', 'POL B4', 'POL B5', 'EEG C1-Ref', 'EEG C2-Ref', 'EEG C3-Ref-0','POL N1', 'POL N2', 'POL N3', 'POL N4', 'POL N5', 'POL N6']\n",
    "hpc_chan2[2] = ['POL B1', 'POL B2', 'POL B3', 'EEG C1-Ref', 'EEG C2-Ref', 'POL D1', 'POL D2', 'POL D3']\n",
    "hpc_chan2[3] = ['POL E1', 'POL E2', 'POL E3']\n",
    "hpc_chan2[4] = ['POL I1', 'POL I2', 'POL I3', 'POL I4', 'POL I5', 'POL I6']\n",
    "hpc_chan2[7] = ['POL I3', 'POL J1', 'POL J2']\n",
    "hpc_chan2[8] = ['POL I1', 'POL I2', 'POL I3', 'POL I4', 'POL I5', 'POL J1', 'POL J2', 'POL J3', 'POL J4', 'POL J5','POL B1', 'POL B2', 'POL B3', 'POL B4', 'POL B5', 'POL B6', 'POL B7', 'EEG C1-Ref', 'EEG C2-Ref', 'EEG C3-Ref', 'EEG C4-Ref']\n",
    "hpc_chan2[9] = ['EEG A1-Ref', 'EEG A2-Ref', 'POL A4', 'POL A5', 'POL A6', 'POL B1', 'POL B2', 'POL B3', 'POL B4', 'POL B5']\n",
    "hpc_chan2[10] = ['POL K1', 'POL K2', 'POL K3', 'POL K4', 'POL K5', 'POL K6', 'POL K7', 'POL L1', 'POL L3', 'POL L4', 'POL B1', 'POL B2', 'POL B3', 'POL B4', 'EEG A1-Ref', 'EEG A2-Ref', 'POL A3', 'POL A4', 'POL A5', 'EEG C3-Ref-0', 'EEG C4-Ref-0']\n",
    "\n",
    "### Use this selection for bipolarizing\n",
    "# hpc_chan2[1] = ['POL B1','POL B2']\n",
    "# hpc_chan2[2] = ['POL B1', 'POL D3']\n",
    "# hpc_chan2[3] = ['POL E1','POL E2']\n",
    "# hpc_chan2[4] = ['POL I2','POL I3']\n",
    "# hpc_chan2[7] = ['POL I3', 'POL I4']\n",
    "# hpc_chan2[8] = ['POL J1','POL J2']\n",
    "\n",
    "# deepInsight_encode =  file_paths[sub]['folder'] + 'HDF5/deepInsight_encode.h5' \n",
    "# fp_plot = file_paths[sub]['folder'] + 'Plot/'\n",
    "# fp_data = file_paths[sub]['folder'] + 'Intermediate_data/'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## necessary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_gamelog(gamelog):\n",
    "\n",
    "    trials_data = {}\n",
    "\n",
    "    reading_navigation_positions = False\n",
    "\n",
    "    for line in gamelog:\n",
    "\n",
    "        if line.startswith('Trial ended'):\n",
    "            trials_data[trial_n]['Trial_ended_time'] = float(line.split(' ')[-1]) \n",
    "\n",
    "            trial_duration = trials_data[trial_n]['Trial_ended_time'] - trials_data[trial_n]['Trial_start_time']\n",
    "            trials_data[trial_n]['trial_duration'] = trial_duration\n",
    "            trials_data[trial_n]['n_of_objects'] = len(trials_data[trial_n]['Objects_location'])\n",
    "\n",
    "            trials_data[trial_n]['Navigation'] = np.array(trials_data[trial_n]['Navigation'])\n",
    "            #trials_data[trial_n]['Navigation'][:,1] = trials_data[trial_n]['Navigation'][:,1] - (trials_data[trial_n]['Navigation'][:,1].max()/2)\n",
    "            ### Compute velocity from position (navigation) coordinates\n",
    "            trial_duration = trials_data[trial_n]['Navigation'][:,0][-1] - trials_data[trial_n]['Navigation'][:,0][0]\n",
    "            # trial_distance in meters\n",
    "            xpos = trials_data[trial_n]['Navigation'][:,1] \n",
    "            ypos = trials_data[trial_n]['Navigation'][:,2] \n",
    "            trial_distance = np.sum(np.abs(np.diff(xpos +1j* ypos)))\n",
    "            trials_data[trial_n]['Velocity'] = trial_distance/trial_duration\n",
    "            trials_data[trial_n]['Velocity_rounded'] = np.around(trials_data[trial_n]['Velocity'],1)\n",
    "            trials_data[trial_n]['Objects_location'] = np.array(trials_data[trial_n]['Objects_location'])\n",
    "\n",
    "            # trial_distance in angles\n",
    "            trial_distance = np.unwrap( np.angle( trials_data[trial_n]['Navigation'][:,1] +1j* trials_data[trial_n]['Navigation'][:,2] ) )\n",
    "            trial_distance = trial_distance[-1] - trial_distance[0]\n",
    "            trials_data[trial_n]['Trial_distance'] = trial_distance\n",
    "            trials_data[trial_n]['trial_navigation_duration'] = np.diff(trials_data[trial_n]['Navigation'][:,0][[0,-1]])[0]\n",
    "\n",
    "            ### cue/sec needs to get how many laps were performed and ajust it to the number of items per every lap (2pi)\n",
    "            this_trial_crossed_objects = trial_distance * trials_data[trial_n]['n_of_objects'] / np.pi*2\n",
    "            trial_cue_per_sec = trials_data[trial_n]['trial_duration'] / this_trial_crossed_objects\n",
    "            trials_data[trial_n]['trial_cue_per_sec'] = trial_cue_per_sec\n",
    "            # n_objs_per_lap = trials_data[trial_n]['Objects_location'].shape[0] \n",
    "            # xpos = trials_data[trial_n]['Navigation'][:,1]\n",
    "            # ypos = trials_data[trial_n]['Navigation'][:,2]\n",
    "            # unwrapped_navigation = np.unwrap(np.angle(xpos+1j*ypos))\n",
    "            # unwrapped_navigation = unwrapped_navigation - unwrapped_navigation[0]\n",
    "            # total_navigated_angles = unwrapped_navigation[-1] / (np.pi*2) \n",
    "            # trial_cue_per_sec = total_navigated_angles * n_objs_per_lap / trials_data[trial_n]['trial_navigation_duration'] \n",
    "            # trials_data[trial_n]['trial_cue_per_sec'] = trial_cue_per_sec\n",
    "\n",
    "            reading_navigation_positions = False\n",
    "\n",
    "        if reading_navigation_positions==False:\n",
    "\n",
    "            if line.startswith('Trial number'): \n",
    "                trial_n = int(line.split(': ')[1][:-1])\n",
    "                trials_data[trial_n] = {}\n",
    "            if line.startswith('Speed'): \n",
    "                trials_data[trial_n]['Speed'] = float(line.split('Speed: ')[1][:-1])\n",
    "            if line.startswith('Ring_size'): \n",
    "                trials_data[trial_n]['Ring_size'] = float(line.split('Ring_size: ')[1][:-1])\n",
    "\n",
    "            if line.startswith('Objects location'):\n",
    "                ### actualItem +\" \"+ itemX +\" \"+ itemZ +\" \"+ itemAngle\n",
    "                trials_data[trial_n]['Objects_location'] = []\n",
    "            if line.startswith('Item:'):\n",
    "                trials_data[trial_n]['Objects_location'].append( np.array(line.split('Item: ')[1][:-1].split(' ')).astype(float) )\n",
    "\n",
    "            if line.startswith('Trial start'):\n",
    "                trials_data[trial_n]['Navigation'] = []\n",
    "                reading_navigation_positions = True\n",
    "                trials_data[trial_n]['Trial_start_time'] = float(line.split(' ')[-1]) \n",
    "\n",
    "            if line.startswith('Question onset'):\n",
    "                trials_data[trial_n]['Testing'] = {}\n",
    "                trials_data[trial_n]['Testing']['Question_onset'] = float(line.split('Question onset ')[1][:-1])\n",
    "\n",
    "            if line.startswith('Testing'): \n",
    "                tmp_line = line[:-1].split(' ')\n",
    "                trials_data[trial_n]['Testing']['response_time'] = float(tmp_line[1])\n",
    "                trials_data[trial_n]['Testing']['cued_object'] = int(tmp_line[3])\n",
    "                trials_data[trial_n]['Testing']['option_1'] = int(tmp_line[5])\n",
    "                trials_data[trial_n]['Testing']['option_2'] = int(tmp_line[7])\n",
    "                trials_data[trial_n]['Testing']['asnwered_object'] = int(tmp_line[9])\n",
    "                trials_data[trial_n]['Testing']['asnwered_key'] = tmp_line[11]\n",
    "\n",
    "        elif reading_navigation_positions==True:\n",
    "            trials_data[trial_n]['Navigation'].append( np.array(line[:-1].split(' ')).astype(float) )\n",
    "\n",
    "    return trials_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interp_f(behavioural_signal, lfp_size):\n",
    "    n_samples = len(behavioural_signal)\n",
    "    x = np.linspace(0, n_samples, num=n_samples, endpoint=True)\n",
    "    interpolate_f = interp1d(x, behavioural_signal, kind='linear')\n",
    "    new_sampling_space = np.linspace(0, n_samples, num=lfp_size, endpoint=True)\n",
    "    return interpolate_f(new_sampling_space)\n",
    "\n",
    "\n",
    "def get_behavioral_position(trials_data, trial_number):\n",
    "    position_array = []\n",
    "    for count in range(len(trials_data[trial_number]['Navigation'])):\n",
    "        time = trials_data[trial_number]['Navigation'][count][0]\n",
    "        x = trials_data[trial_number]['Navigation'][count][1]\n",
    "        y = trials_data[trial_number]['Navigation'][count][2]\n",
    "        position_array.append([trial_number, time, x, y])\n",
    "        \n",
    "    return np.array(position_array)\n",
    "\n",
    "\n",
    "'''\n",
    "Extract navigation data from recording txt file\n",
    "Return:\n",
    "    data selected from hippocampol channel, \n",
    "    lfp_theta_filtered, applied norch and theta filter on raw data\n",
    "    trials_data, extract from game log, see def struct_gamelog\n",
    "    event_samples, TTL information and index for navigation start, end...etc\n",
    "    int(raw.info['sfreq']) s_frequency info\n",
    "'''\n",
    "def get_subject_data(sub, file_paths, hpc_chan2):\n",
    "\n",
    "    # Load brain recordings\n",
    "    raw = mne.io.read_raw_edf(file_paths[sub]['recordings'])\n",
    "    print(\"all channel name:\", raw.ch_names)\n",
    "    #print(np.shape(raw))\n",
    "    # Load TTL events\n",
    "    TTL = pd.read_csv(file_paths[sub]['ttl'],\n",
    "                      sep=' ',\n",
    "                      names=['time', 'type', 'n'])\n",
    "    #print(TTL)\n",
    "\n",
    "    # Get hippocampal channels of this subject\n",
    "    sub_hpc_chans = hpc_chan2[sub]\n",
    "    data = raw.get_data(picks=sub_hpc_chans)\n",
    "\n",
    "    # Load videoGame data and structure it by trials\n",
    "    gamelog = []\n",
    "    with open(file_paths[sub]['game'], 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            gamelog.append(line)\n",
    "    trials_data = structure_gamelog(gamelog)\n",
    "\n",
    "    ### Load the signal\n",
    "    # Here loading 2 signals in the Amygdala. This will be specific for each patient.\n",
    "    lfps = raw.get_data(picks=sub_hpc_chans)\n",
    "\n",
    "    ## Notch is done to remove the noise from the power line in the building. Since China operates on a 220V voltage and 50Hz and remove the 50Hz and its harmonics (100, 150, etc) to the signal.\n",
    "    lfp_bp_notch = mne.filter.notch_filter(lfps,\n",
    "                                           raw.info['sfreq'],\n",
    "                                           [50., 100., 150., 200.],\n",
    "                                           notch_widths=.1)\n",
    "#   lfp_bp_notch = lfp_bp_notch[0] - lfp_bp_notch[1]\n",
    "    low_freq = 2\n",
    "    high_freq = 10\n",
    "\n",
    "    lfp_theta_filtered = mne.filter.filter_data(lfp_bp_notch, int(raw.info['sfreq']), low_freq, high_freq, verbose=False )\n",
    "\n",
    "    ### TTL markers\n",
    "    event_samples = np.vstack((\n",
    "        TTL[TTL['type'] == 2]['time'].values,\n",
    "        TTL[TTL['type'] == 3]['time'].values,\n",
    "        TTL[TTL['type'] == 4]['time'].values,\n",
    "        TTL[TTL['type'] == 5]['time'].values,\n",
    "    )).T\n",
    "\n",
    "    return data, lfp_theta_filtered, trials_data, event_samples, int(raw.info['sfreq'])\n",
    "\n",
    "\n",
    "'''\n",
    "Deal with ieeg signal data\n",
    "Return: \n",
    "a dict with essential information\n",
    "physilogical data: a list of the ieeg signal between navigation for all trials\n",
    "timestamps: a list of index matching physilogical data\n",
    "position_2d: coordinate..ish matching each timestamp\n",
    "event_marker: \n",
    "'''\n",
    "def get_preprocess_data(trials_data,markers,physilogical_data,start_end_indice=[0,1],test=False): #trials, event_sample, notch_filtered_data\n",
    "    \n",
    "    '''\n",
    "    start_end_indice:\n",
    "        markers[:][0] the start of one trial\n",
    "        markers[:][1] the end of one trial\n",
    "        markers[:][2] the onset of the testing question\n",
    "        markers[:][3] the onset of response\n",
    "    test: \n",
    "        True: decode the recall part, no real output(position)\n",
    "    '''\n",
    "    physilogical_data_navi= {}\n",
    "\n",
    "    for chan in range(physilogical_data.shape[0]):\n",
    "        \n",
    "        for trial_num in range(min(len(trials_data), len(markers))):  \n",
    "            behavioural_signal = get_behavioral_position(trials_data, trial_num)\n",
    "            navi_start = int(markers[trial_num][start_end_indice[0]])\n",
    "            navi_stop = int(markers[trial_num][start_end_indice[1]])\n",
    "            lfp_size = abs(navi_stop - navi_start)\n",
    "            \n",
    "            if (chan == 0) & (trial_num == 0):\n",
    "                start_array = np.array([lfp_size])\n",
    "                timestamps = np.linspace(navi_start,navi_stop-1,lfp_size, dtype=int)\n",
    "                if test == False :\n",
    "                    position_2d = np.vstack(( interp_f(behavioural_signal.T[2], lfp_size) , interp_f(behavioural_signal.T[3], lfp_size)))\n",
    "                \n",
    "            if (chan == 0) & (trial_num > 0):\n",
    "                start_array = np.hstack((start_array,np.array([int(start_array[trial_num-1])+lfp_size])))\n",
    "                timestamps = np.hstack(( timestamps, np.linspace(navi_start,navi_stop-1,lfp_size, dtype=int) ))\n",
    "                if test == False :\n",
    "                    position_2d = np.hstack((position_2d, np.vstack(( interp_f(behavioural_signal.T[2], lfp_size) , interp_f(behavioural_signal.T[3], lfp_size)))  ))\n",
    "                \n",
    "            if trial_num == 0:\n",
    "                physilogical_data_navi[chan]= physilogical_data[chan][navi_start:navi_stop]\n",
    "                \n",
    "            if trial_num > 0:\n",
    "                physilogical_data_navi[chan]  = np.hstack((physilogical_data_navi[chan], physilogical_data[chan][navi_start:navi_stop] ))\n",
    "    \n",
    "    print(np.shape(timestamps))\n",
    "    print(np.shape(start_array))\n",
    "    print(np.shape(np.array([physilogical_data_navi[i] for i in range(len(physilogical_data_navi))]).T))\n",
    "    if test == True :\n",
    "        return {\n",
    "            'physilogical_data': np.array([physilogical_data_navi[i] for i in range(len(physilogical_data_navi))]).T,\n",
    "            'timestamps': timestamps,\n",
    "            'event_marker_each_trial': start_array\n",
    "        }\n",
    "    if test == False :               \n",
    "        return {\n",
    "            'physilogical_data': np.array([physilogical_data_navi[i] for i in range(len(physilogical_data_navi))]).T,\n",
    "            'timestamps': timestamps,\n",
    "            'position_2d': position_2d,\n",
    "            'event_marker_each_trial': start_array\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Number of Theta Cycles from physilogical data nad event sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bycycle.features import compute_features \n",
    "\n",
    "for i in [1,2,3,4,7,8,9,10]:\n",
    "    sub = i\n",
    "    raw, lfp_theta_filtered, trials_data, event_samples, sfreq = get_subject_data(sub, file_paths, hpc_chan2)\n",
    "    print(min(len(event_samples), len(trials_data)))\n",
    "    preprocess_data = get_preprocess_data(trials_data,event_samples,lfp_theta_filtered)\n",
    "\n",
    "    raw_data = preprocess_data['physilogical_data']\n",
    "    timestamps = preprocess_data['timestamps']\n",
    "    # plt.title('theta_cycle')\n",
    "    # y_axis = raw_data[:, 0]\n",
    "    # p1 = plt.plot(y_axis, marker='o', color = 'green')\n",
    "\n",
    "    print(np.shape(timestamps))\n",
    "    print(\"?\", np.shape(raw_data))\n",
    "\n",
    "    #Set trial number\n",
    "    trial_total_num = min(len(trials_data), len(event_samples))\n",
    "    if sub == 8:\n",
    "        trial_total_num = 37\n",
    "    channel_num = np.shape(raw_data)[1]\n",
    "    theta_cycle_record = {}\n",
    "    theta_cycle_record['Velocity'] = []\n",
    "    theta_cycle_record['cue_density'] = []\n",
    "    theta_cycle_record['trial_cue_per_sec'] = []\n",
    "    #get timestamp for trial to start and to end\n",
    "    for channel in range(channel_num):\n",
    "        theta_cycle_record[hpc_chan2[sub][channel]] = []\n",
    "        i = 0\n",
    "        for trial_num in range(trial_total_num):\n",
    "\n",
    "            navi_start = int(event_samples[trial_num][0])\n",
    "            navi_end = int(event_samples[trial_num][1])\n",
    "\n",
    "            #Find the index in the preprocess signal array that match the timestamps\n",
    "            start_index = np.where(timestamps == navi_start)[0][0] if np.any(timestamps == navi_start) else None\n",
    "            end_index = np.where(timestamps == navi_end - 1)[0][0] if np.any(timestamps == navi_end - 1) else None\n",
    "            #print(\"got one\", start_index, end_index, i)\n",
    "            i += 1\n",
    "            assert(timestamps[start_index] == navi_start)\n",
    "            physilogical_data_navigation = raw_data[start_index:end_index + 1, channel]\n",
    "            count = 0\n",
    "            index = 0\n",
    "            burst_kwargs = {'amplitude_fraction_threshold': .2,\n",
    "                'amplitude_consistency_threshold': .5,\n",
    "                'period_consistency_threshold': .5,\n",
    "                'monotonicity_threshold': .8,\n",
    "                'N_cycles_min': 4}\n",
    "\n",
    "            f_range = (2, 10)\n",
    "            df = compute_features(physilogical_data_navigation, sfreq, f_range)\n",
    "\n",
    "\n",
    "            theta_cycle_record[hpc_chan2[sub][channel]].append(np.shape(df)[0] / trials_data[trial_num]['trial_navigation_duration'])\n",
    "\n",
    "    for trial_num in range(trial_total_num):\n",
    "        theta_cycle_record['Velocity'].append(trials_data[trial_num]['Velocity'])\n",
    "        theta_cycle_record['cue_density'].append(np.pi * 2 * trials_data[trial_num]['Ring_size'] / trials_data[trial_num]['n_of_objects'])#? cue density?\n",
    "        theta_cycle_record['trial_cue_per_sec'].append(trials_data[trial_num]['trial_cue_per_sec'])\n",
    "\n",
    "    \n",
    "    print(theta_cycle_record)\n",
    "    pd.DataFrame(theta_cycle_record).to_csv(f\"theta_cycles/theta_cycle_second_{sub}_{file_paths[sub]['info']['name']}.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in [1,2,3,4,7,8,9,10]:    \n",
    "    theta_cycle_record = pd.read_csv(f\"theta_cycles/theta_cycle_second_{sub}_{file_paths[sub]['info']['name']}.csv\").to_numpy()\n",
    "    chan_num = np.shape(theta_cycle_record)[1] - 3\n",
    "    rows, cols = chan_num, 3\n",
    "    fig,ax = plt.subplots(rows, cols, figsize=(20, 5*chan_num))\n",
    "    for chan in range(chan_num):\n",
    "        y = theta_cycle_record[:, chan+3]\n",
    "        x = theta_cycle_record[:,0]\n",
    "        p = ax[chan, 0].scatter(x, y, marker='o', label=hpc_chan2[sub][0], color = 'green')\n",
    "        p.set_label(hpc_chan2[sub][chan])\n",
    "        ax[chan, 0].legend()\n",
    "        ax[chan, 0].set_xlabel(\"velocity\")\n",
    "        ax[chan, 0].set_ylabel(\"theta cycles\")\n",
    "        x = theta_cycle_record[:,1]\n",
    "        ax[chan, 1].scatter(x, y, marker='o', label=hpc_chan2[sub][0], color = 'green')\n",
    "        ax[chan, 1].set_xlabel(\"cue_density\")\n",
    "        ax[chan, 0].legend()\n",
    "        x = theta_cycle_record[:,2]\n",
    "        ax[chan, 2].scatter(x, y,  marker='o', label=hpc_chan2[sub][1], color = 'green')\n",
    "        ax[chan, 2].set_xlabel(\"cue_per_second\")\n",
    "        ax[chan, 0].legend()   \n",
    "    fig.savefig(f\"C:/Users/River/23summer/dku/ieeg/theta_cycle_graph_cue_per_trial/theta_cycle_second_{sub}_{file_paths[sub]['info']['name']}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in [1,2,3,4,7,8,9,10]:   \n",
    "    theta_cycle_record = pd.read_csv(f\"theta_cycles/theta_cycle_second_{sub}_{file_paths[sub]['info']['name']}.csv\").to_numpy()\n",
    "    ordered_record = theta_cycle_record[theta_cycle_record[:, 0].argsort()]\n",
    "    groups_velocity = {}\n",
    "    groups_cue_density = {}\n",
    "    groups_cue_per_sec = {}\n",
    "    # start_index = 0\n",
    "    # count = 0\n",
    "    # element_count = 0\n",
    "    # for i in range(np.shape(ordered_record)[0] - 1):\n",
    "    #     element_count += 1\n",
    "    #     if ordered_record[i + 1, 0] - ordered_record[i, 0] > 0.0001:\n",
    "    #         print(\"a new velocity group, total \", element_count, count)\n",
    "    #         groups_velocity[count] = np.copy(ordered_record[start_index:(i + 1)])\n",
    "    #         start_index = i + 1\n",
    "    #         count += 1\n",
    "    #         element_count = 0\n",
    "    # if start_index <= np.shape(ordered_record)[0]:\n",
    "    #     print(\"a new velocity group, total \", element_count, count)\n",
    "    #     groups_velocity[count] = np.copy(ordered_record[start_index:])\n",
    "    # print(groups_velocity.keys())\n",
    "\n",
    "\n",
    "    # ordered_record = theta_cycle_record[theta_cycle_record[:, 1].argsort()]\n",
    "    # start_index = 0\n",
    "    # count = 0\n",
    "    # element_count = 0\n",
    "    # for i in range(np.shape(ordered_record)[0] - 1):\n",
    "    #     element_count += 1\n",
    "    #     if ordered_record[i + 1, 1] - ordered_record[i, 1] > 0.01:\n",
    "    #         print(\"a new velocity group, total \", element_count, count)\n",
    "    #         groups_cue_density[count] = np.copy(ordered_record[start_index:(i + 1)])\n",
    "    #         start_index = i + 1\n",
    "    #         count += 1\n",
    "    #         element_count = 0\n",
    "    # if start_index <= np.shape(ordered_record)[0]:\n",
    "    #     print(\"a new cue_density group, total \", element_count, count)\n",
    "    #     groups_cue_density[count] = np.copy(ordered_record[start_index:])\n",
    "    # print(groups_cue_density.keys())\n",
    "\n",
    "\n",
    "    ordered_record = theta_cycle_record[theta_cycle_record[:, 2].argsort()]\n",
    "    start_index = 0\n",
    "    count = 0\n",
    "    element_count = 0\n",
    "    for i in range(np.shape(ordered_record)[0] - 1):\n",
    "        element_count += 1\n",
    "        if ordered_record[i + 1, 2] - ordered_record[i, 2] > 0.0001:\n",
    "            print(\"a new cue_per_sec group, total \", element_count, count)\n",
    "            groups_cue_per_sec[ordered_record[i, 2]] = np.copy(ordered_record[start_index:(i + 1)])\n",
    "            start_index = i + 1\n",
    "            count += 1\n",
    "            element_count = 0\n",
    "    if start_index <= np.shape(ordered_record)[0]:\n",
    "        print(\"a new velocity group, total \", element_count, count)\n",
    "        groups_cue_per_sec[ordered_record[i, 2]] = np.copy(ordered_record[start_index:])\n",
    "\n",
    "    from scipy import stats\n",
    "    mean = np.zeros((len(hpc_chan2[sub]), len(groups_cue_per_sec.keys())))\n",
    "    sem = np.zeros((len(hpc_chan2[sub]), len(groups_cue_per_sec.keys())))\n",
    "    count = 0\n",
    "    for key in groups_cue_per_sec.keys():\n",
    "        mean[:, count] = np.mean(groups_cue_per_sec[key], axis = 0)[3:]\n",
    "        sem[:, count] = stats.sem(groups_cue_per_sec[key], axis = 0)[3:]\n",
    "        count += 1\n",
    "\n",
    "    chan_num = np.shape(theta_cycle_record)[1] - 3\n",
    "    rows, cols = chan_num, 1\n",
    "    fig,ax = plt.subplots(rows, cols, figsize=(10, 5*chan_num))\n",
    "    x = list(groups_cue_per_sec.keys())\n",
    "    for chan in range(chan_num):\n",
    "        y = mean[chan, :]\n",
    "        err = sem[chan, :]\n",
    "        p = ax[chan].bar(x, y, yerr = err, width = 0.01)\n",
    "        p.set_label(hpc_chan2[sub][chan])\n",
    "        ax[chan].set_ylim([3.5, 5.7])\n",
    "        ax[chan].legend()\n",
    "        ax[chan].set_xlabel(\"cue_per_sec\")\n",
    "        ax[chan].set_ylabel(\"theta cycles\")\n",
    "    fig.savefig(f\"C:/Users/River/23summer/dku/ieeg/theta_cycle_graph_cue_per_trial/theta_cycle_second_avg_{sub}_{file_paths[sub]['info']['name']}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "mean = np.zeros((len(hpc_chan2[sub]), len(groups_cue_per_sec.keys())))\n",
    "sem = np.zeros((len(hpc_chan2[sub]), len(groups_cue_per_sec.keys())))\n",
    "count = 0\n",
    "for key in groups_cue_per_sec.keys():\n",
    "    mean[:, count] = np.mean(groups_cue_per_sec[key], axis = 0)[3:]\n",
    "    sem[:, count] = stats.sem(groups_cue_per_sec[key], axis = 0)[3:]\n",
    "    count += 1\n",
    "\n",
    "chan_num = np.shape(theta_cycle_record)[1] - 3\n",
    "rows, cols = chan_num, 1\n",
    "fig,ax = plt.subplots(rows, cols, figsize=(10, 5*chan_num))\n",
    "x = list(groups_cue_per_sec.keys())\n",
    "for chan in range(chan_num):\n",
    "    y = mean[chan, :]\n",
    "    err = sem[chan, :]\n",
    "    p = ax[chan].bar(x, y, yerr = err, width = 0.05)\n",
    "    p.set_label(hpc_chan2[sub][chan])\n",
    "    ax[chan].legend()\n",
    "    ax[chan].set_xlabel(\"cue_per_sec\")\n",
    "    ax[chan].set_ylabel(\"theta cycles\")\n",
    "fig.savefig(f\"C:/Users/River/23summer/dku/ieeg/theta_cycle_graph_cue_per_trial/theta_cycle_avg_{sub}_{file_paths[sub]['info']['name']}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 1\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "theta_cycle_record = pd.read_csv(f\"theta_cycles/theta_cycle_{sub}_{file_paths[sub]['info']['name']}.csv\").to_numpy()\n",
    "ordered_record = theta_cycle_record[theta_cycle_record[:, 1].argsort()]\n",
    "x_axis = ordered_record[:,1]\n",
    "y_axis = ordered_record[:,3]\n",
    "y_axis2 = ordered_record[:,4]\n",
    "p1 = plt.scatter(x_axis, y_axis, marker='o', label=hpc_chan2[sub][0], color = 'green')\n",
    "plt.xlabel('cue_density')\n",
    "plt.ylabel('number_of_cycles')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "p2 = plt.scatter(x_axis, y_axis2, marker='o', label=hpc_chan2[sub][1], color = 'red')\n",
    "plt.title('cue_density')\n",
    "plt.xlabel('cue_density')\n",
    "plt.ylabel('number_of_cycles')\n",
    "plt.legend()\n",
    "#plt.savefig(f\"C:/Users/River/23summer/dku/ieeg/cue_density/cue_density_{sub}_{file_paths[sub]['info']['name']}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 1\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "theta_cycle_record = pd.read_csv(f\"theta_cycles/theta_cycle_{sub}_{file_paths[sub]['info']['name']}.csv\").to_numpy()\n",
    "ordered_record = theta_cycle_record[theta_cycle_record[:, 1].argsort()]\n",
    "x_axis = ordered_record[:,2]\n",
    "y_axis = ordered_record[:,3]\n",
    "y_axis2 = ordered_record[:,4]\n",
    "p1 = plt.scatter(x_axis, y_axis, marker='o', label=hpc_chan2[sub][0], color = 'green')\n",
    "plt.xlabel('cue_per_second')\n",
    "plt.ylabel('number_of_cycles')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "p2 = plt.scatter(x_axis, y_axis2, marker='o', label=hpc_chan2[sub][1], color = 'red')\n",
    "plt.title('cue_per_second')\n",
    "plt.xlabel('cue_per_second')\n",
    "plt.ylabel('number_of_cycles')\n",
    "plt.legend()\n",
    "plt.savefig(f\"C:/Users/River/23summer/dku/ieeg/theta_cycle_graph_cue_per_trial/theta_cycle_{sub}_{file_paths[sub]['info']['name']}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 1\n",
    "theta_cycle_record = pd.read_csv(f\"theta_cycles/theta_cycle_{sub}_{file_paths[sub]['info']['name']}.csv\").to_numpy()\n",
    "theta_cycle_record[:,0] = np.round(theta_cycle_record[:,0], 3)\n",
    "ordered_record = theta_cycle_record[theta_cycle_record[:, 0].argsort()]\n",
    "print(ordered_record[:,0])\n",
    "print(ordered_record[:,1])\n",
    "index_start = 0\n",
    "count = 0\n",
    "for i in range(np.shape(ordered_record)[0]):\n",
    "    if ordered_record[i, 0] != ordered_record[index_start, 0]:\n",
    "        plt.title('cue_density')\n",
    "        x_axis = ordered_record[index_start:i,1]\n",
    "        y_axis = ordered_record[index_start:i,3]\n",
    "        p1 = plt.scatter(x_axis, y_axis, marker='o', label=hpc_chan2[sub][0], color = 'green')\n",
    "        if np.shape(ordered_record)[1] == 5:\n",
    "            y_axis = ordered_record[index_start:i,4]\n",
    "            p2 = plt.scatter(x_axis, y_axis, marker='o', label=hpc_chan2[sub][1], color = 'red')\n",
    "        plt.xlabel('cue_density')\n",
    "        plt.ylabel('number_of_circles')\n",
    "        #plt.legend()\n",
    "        #plt.savefig(f\"C:/Users/River/23summer/dku/ieeg/cue_density/cue_density__{count}_{sub}_{file_paths[sub]['info']['name']}.png\")\n",
    "        count += 1\n",
    "        index_start = i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
